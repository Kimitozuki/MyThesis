{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import win_precise_time as wpt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Command to start Tensorboard: `tensorboard --logdir <log-location>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 9\n",
    "BATCH_SIZE = 32\n",
    "SAVE_DIR = 'models' \n",
    "LOG_DIR = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets1.h5','r') as hf:\n",
    "    y_train = np.array(hf.get('y_train'))\n",
    "    y_val = np.array(hf.get('y_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wildan Mufid R\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: b'batuk',\n",
       " 1: b'demam',\n",
       " 2: b'gigi',\n",
       " 3: b'kepala',\n",
       " 4: b'minum',\n",
       " 5: b'obat',\n",
       " 6: b'perut',\n",
       " 7: b'resep',\n",
       " 8: b'sakit'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHE = OneHotEncoder(sparse=False).fit(y_train.reshape(-1, 1))\n",
    "\n",
    "decoder = {i : sign for i, sign in enumerate(OHE.categories_[0])}\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 9)\n",
      "(205, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train = OHE.transform(y_train.reshape(-1, 1))\n",
    "y_val = OHE.transform(y_val.reshape(-1, 1))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Layer):\n",
    "    def __init__(self, units, return_sequences=False, **kwargs):\n",
    "        super(LSTM, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self.W_in = self.add_weight(\"W_in\", (input_dim, self.units * 4), initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.W_hiddenState = self.add_weight(\n",
    "            \"W_hiddenState\", (self.units, self.units * 4), initializer=\"orthogonal\", trainable=True\n",
    "        )\n",
    "        self.bias = self.add_weight(\"bias\", (self.units * 4,), initializer=\"zeros\", trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        hidden = tf.zeros((inputs.shape[0], self.units))\n",
    "        cell = tf.zeros((inputs.shape[0], self.units))\n",
    "        output = []\n",
    "        for i in range(inputs.shape[1]):\n",
    "            x_in = inputs[:, i, :]\n",
    "            z = tf.matmul(x_in, self.W_in) + tf.matmul(hidden, self.W_hiddenState) + self.bias\n",
    "            zi, zf, zc, zo = tf.split(z, 4, axis=1)\n",
    "            forget = tf.keras.activations.sigmoid(zf)\n",
    "            inp = tf.keras.activations.sigmoid(zi)\n",
    "            cell = forget * cell + inp * tf.keras.activations.tanh(zc)\n",
    "            out = tf.keras.activations.sigmoid(zo)\n",
    "            hidden = out * tf.keras.activations.tanh(cell)\n",
    "            if self.return_sequences:\n",
    "                output.append(hidden)\n",
    "        if self.return_sequences:\n",
    "            output = tf.stack(output, axis=1)\n",
    "        else:\n",
    "            output = hidden\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bidirection LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(Layer):\n",
    "    def __init__(self, units, return_sequences=False, **kwargs):\n",
    "        super(BidirectionalLSTM, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "    def build(self, input_shape):       \n",
    "        self.forward_lstm = LSTM(\n",
    "            units=self.units,\n",
    "            return_sequences=self.return_sequences,\n",
    "        )\n",
    "        \n",
    "        self.backward_lstm = LSTM(\n",
    "            units=self.units,\n",
    "            return_sequences=self.return_sequences,\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        forward_output = self.forward_lstm(inputs)\n",
    "        backward_output = self.backward_lstm(tf.reverse(inputs, axis=[1]))\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            backward_output = tf.reverse(backward_output, axis=[1])\n",
    "\n",
    "        return tf.concat([forward_output, backward_output], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(Layer):\n",
    "    def __init__(self, epsilon=1e-3, momentum=0.99, **kwargs):\n",
    "        super(BatchNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = self.add_weight(\"gamma\", shape=(input_shape[-1],), initializer=\"ones\", trainable=True)\n",
    "        self.beta = self.add_weight(\"beta\", shape=(input_shape[-1],), initializer=\"zeros\", trainable=True)\n",
    "        self.moving_mean = self.add_weight(\"moving_mean\", shape=(input_shape[-1],), initializer=\"zeros\", trainable=False)\n",
    "        self.moving_variance = self.add_weight(\"moving_variance\", shape=(input_shape[-1],), initializer=\"ones\", trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            batch_mean, batch_variance = tf.nn.moments(inputs, axes=[0], keepdims=False)\n",
    "            \n",
    "            update_moving_mean = tf.assign_sub(self.moving_mean, (1 - self.momentum) * (self.moving_mean - batch_mean))\n",
    "            update_moving_variance = tf.assign_sub(self.moving_variance, (1 - self.momentum) * (self.moving_variance - batch_variance))\n",
    "            \n",
    "            with tf.control_dependencies([update_moving_mean, update_moving_variance]):\n",
    "                normalized_inputs = (inputs - batch_mean) / tf.sqrt(batch_variance + self.epsilon)\n",
    "        else:\n",
    "            normalized_inputs = (inputs - self.moving_mean) / tf.sqrt(self.moving_variance + self.epsilon)\n",
    "        \n",
    "        scaled_inputs = self.gamma * normalized_inputs + self.beta\n",
    "        return scaled_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Form the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(input_shape):\n",
    "    return tf.keras.models.Sequential([\n",
    "        LSTM(512, return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(256, return_sequences=True),\n",
    "        LSTM(128),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_LABELS, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "\n",
    "def bilstm_model(input_shape):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape),\n",
    "        Bidirectional(LSTM(512, return_sequences=True, input_shape=input_shape)),\n",
    "        Bidirectional(LSTM(256, return_sequences=True)),\n",
    "        Bidirectional(LSTM(128)),\n",
    "        BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_LABELS, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoChangeStop(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_loss', patience=7, tolerance=.05):\n",
    "        super(NoChangeStop, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.tolerance = tolerance\n",
    "        self.wait = 0\n",
    "        self.last_value = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_value = logs.get(self.monitor)\n",
    "        \n",
    "        if self.last_value is None:\n",
    "            self.last_value = current_value\n",
    "        elif abs(current_value - self.last_value) <= self.tolerance:\n",
    "            self.wait += 1\n",
    "            if self.wait == self.patience:\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "            self.last_value = current_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noChangeStop = NoChangeStop(patience=7, tolerance=.05)\n",
    "\n",
    "def checkpoint(fname):\n",
    "    return ModelCheckpoint(f\"{SAVE_DIR}/{fname}.h5\", monitor='val_accuracy', mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Crossentropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalCrossentropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, name='custom_categorical_crossentropy', **kwargs):\n",
    "        super(CategoricalCrossentropy, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "        \n",
    "        loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super(CategoricalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        values = tf.cast(tf.equal(y_true, y_pred), dtype=tf.float32)\n",
    "       \n",
    "        self.total.assign_add(tf.reduce_sum(values))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1-Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.true_positives = self.add_weight('true_positives', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_positives = self.add_weight('false_positives', shape=(num_classes,), initializer='zeros')\n",
    "        self.false_negatives = self.add_weight('false_negatives', shape=(num_classes,), initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        for class_idx in range(self.num_classes):\n",
    "            tp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, class_idx), tf.equal(y_pred, class_idx)), dtype=tf.float32))\n",
    "            fp = tf.reduce_sum(tf.cast(tf.logical_and(tf.not_equal(y_true, class_idx), tf.equal(y_pred, class_idx)), dtype=tf.float32))\n",
    "            fn = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, class_idx), tf.not_equal(y_pred, class_idx)), dtype=tf.float32))\n",
    "            \n",
    "            self.true_positives[class_idx].assign_add(tp)\n",
    "            self.false_positives[class_idx].assign_add(fp)\n",
    "            self.false_negatives[class_idx].assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        precision = self.true_positives / (self.true_positives + self.false_positives + epsilon)\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + epsilon)\n",
    "        f1 = 2.0 * (precision * recall) / (precision + recall + epsilon)\n",
    "        return tf.reduce_mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(fname, history):\n",
    "    with h5py.File(fname,'w') as hf:\n",
    "        hf.create_dataset('accuracy', data = np.array(history.history['accuracy']))\n",
    "        hf.create_dataset('val_accuracy', data = np.array(history.history['val_accuracy']))\n",
    "        hf.create_dataset('f1_score', data = np.array(history.history['f1_score']))\n",
    "        hf.create_dataset('val_f1_score', data = np.array(history.history['val_f1_score']))\n",
    "        hf.create_dataset('loss', data = np.array(history.history['loss']))\n",
    "        hf.create_dataset('val_loss', data = np.array(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(fname, history):\n",
    "    with h5py.File(f'logs/{fname}.h5','w') as hf:\n",
    "        hf.create_dataset('accuracy', data = np.array(history.history['accuracy']))\n",
    "        hf.create_dataset('val_accuracy', data = np.array(history.history['val_accuracy']))\n",
    "        hf.create_dataset('f1_score', data = np.array(history.history['f1_score']))\n",
    "        hf.create_dataset('val_f1_score', data = np.array(history.history['val_f1_score']))\n",
    "        hf.create_dataset('loss', data = np.array(history.history['loss']))\n",
    "        hf.create_dataset('val_loss', data = np.array(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets 1\n",
    "Base Component (Face, Body, Right Hand, and Left Hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets1.h5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    x_val = np.array(hf.get('x_val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 34, 512)           4454400   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 34, 256)           787456    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,450,121\n",
      "Trainable params: 5,449,865\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss= CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  CategoricalAccuracy(),\n",
    "                  F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 5/26 [====>.........................] - ETA: 0s - loss: 2.2304 - accuracy: 0.2375 - f1_score: 0.1669 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0315s vs `on_train_batch_end` time: 0.0336s). Check your callbacks.\n",
      "26/26 [==============================] - 12s 95ms/step - loss: 1.6654 - accuracy: 0.4118 - f1_score: 0.3505 - val_loss: 1.6802 - val_accuracy: 0.5171 - val_f1_score: 0.4772 - relative: 20.9934\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.0567 - accuracy: 0.6495 - f1_score: 0.6368 - val_loss: 1.4372 - val_accuracy: 0.5902 - val_f1_score: 0.6088 - relative: 22.0584\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.8251 - accuracy: 0.7341 - f1_score: 0.7295 - val_loss: 1.1231 - val_accuracy: 0.7220 - val_f1_score: 0.7301 - relative: 23.4442\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7015 - accuracy: 0.7537 - f1_score: 0.7496 - val_loss: 0.9962 - val_accuracy: 0.6976 - val_f1_score: 0.7103 - relative: 24.8342\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5986 - accuracy: 0.7892 - f1_score: 0.7868 - val_loss: 0.9150 - val_accuracy: 0.6732 - val_f1_score: 0.6668 - relative: 25.7982\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.4521 - accuracy: 0.8517 - f1_score: 0.8489 - val_loss: 0.8289 - val_accuracy: 0.7171 - val_f1_score: 0.7138 - relative: 26.7580\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.4841 - accuracy: 0.8382 - f1_score: 0.8373 - val_loss: 0.6668 - val_accuracy: 0.7659 - val_f1_score: 0.7771 - relative: 27.7069\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.3984 - accuracy: 0.8615 - f1_score: 0.8592 - val_loss: 0.5427 - val_accuracy: 0.8049 - val_f1_score: 0.8110 - relative: 29.1300\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2852 - accuracy: 0.9007 - f1_score: 0.8994 - val_loss: 0.6618 - val_accuracy: 0.7854 - val_f1_score: 0.7841 - relative: 30.5024\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2871 - accuracy: 0.9020 - f1_score: 0.9001 - val_loss: 0.6392 - val_accuracy: 0.7707 - val_f1_score: 0.7804 - relative: 31.4096\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.3255 - accuracy: 0.8934 - f1_score: 0.8920 - val_loss: 0.5461 - val_accuracy: 0.8098 - val_f1_score: 0.8192 - relative: 32.3481\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.2802 - accuracy: 0.9105 - f1_score: 0.9102 - val_loss: 0.5332 - val_accuracy: 0.8341 - val_f1_score: 0.8435 - relative: 33.6511\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2267 - accuracy: 0.9216 - f1_score: 0.9202 - val_loss: 0.5666 - val_accuracy: 0.8098 - val_f1_score: 0.8101 - relative: 35.0393\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.2702 - accuracy: 0.9093 - f1_score: 0.9086 - val_loss: 0.5280 - val_accuracy: 0.8000 - val_f1_score: 0.8009 - relative: 36.0054\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.2610 - accuracy: 0.9167 - f1_score: 0.9162 - val_loss: 0.4607 - val_accuracy: 0.8537 - val_f1_score: 0.8561 - relative: 36.9335\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.2302 - accuracy: 0.9228 - f1_score: 0.9214 - val_loss: 0.5001 - val_accuracy: 0.8293 - val_f1_score: 0.8363 - relative: 38.3626\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1883 - accuracy: 0.9424 - f1_score: 0.9419 - val_loss: 0.4782 - val_accuracy: 0.8341 - val_f1_score: 0.8356 - relative: 39.2857\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.1323 - accuracy: 0.9571 - f1_score: 0.9565 - val_loss: 0.4761 - val_accuracy: 0.8829 - val_f1_score: 0.8836 - relative: 40.1880\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1678 - accuracy: 0.9424 - f1_score: 0.9421 - val_loss: 0.6204 - val_accuracy: 0.8341 - val_f1_score: 0.8430 - relative: 41.7499\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.1756 - accuracy: 0.9363 - f1_score: 0.9352 - val_loss: 0.4936 - val_accuracy: 0.8634 - val_f1_score: 0.8682 - relative: 42.7448\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1303 - accuracy: 0.9596 - f1_score: 0.9593 - val_loss: 0.6191 - val_accuracy: 0.8341 - val_f1_score: 0.8381 - relative: 43.7206\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1228 - accuracy: 0.9645 - f1_score: 0.9638 - val_loss: 0.5909 - val_accuracy: 0.8585 - val_f1_score: 0.8619 - relative: 44.6446\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1286 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.6302 - val_accuracy: 0.8195 - val_f1_score: 0.8206 - relative: 45.5998\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.1820 - accuracy: 0.9412 - f1_score: 0.9410 - val_loss: 0.6038 - val_accuracy: 0.8195 - val_f1_score: 0.8213 - relative: 46.7448\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.1319 - accuracy: 0.9571 - f1_score: 0.9569 - val_loss: 0.7142 - val_accuracy: 0.8146 - val_f1_score: 0.8175 - relative: 47.8259\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.1691 - accuracy: 0.9485 - f1_score: 0.9478 - val_loss: 0.7322 - val_accuracy: 0.7902 - val_f1_score: 0.7962 - relative: 48.8502\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2335 - accuracy: 0.9301 - f1_score: 0.9296 - val_loss: 0.6593 - val_accuracy: 0.8390 - val_f1_score: 0.8436 - relative: 49.7952\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.1173 - accuracy: 0.9620 - f1_score: 0.9615 - val_loss: 0.5650 - val_accuracy: 0.8537 - val_f1_score: 0.8585 - relative: 50.8730\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1883 - accuracy: 0.9473 - f1_score: 0.9466 - val_loss: 0.6015 - val_accuracy: 0.8293 - val_f1_score: 0.8356 - relative: 52.0737\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.2169 - accuracy: 0.9301 - f1_score: 0.9295 - val_loss: 0.6369 - val_accuracy: 0.8244 - val_f1_score: 0.8279 - relative: 53.0502\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1624 - accuracy: 0.9498 - f1_score: 0.9493 - val_loss: 0.5199 - val_accuracy: 0.8537 - val_f1_score: 0.8595 - relative: 53.9864\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1761 - accuracy: 0.9498 - f1_score: 0.9492 - val_loss: 0.5156 - val_accuracy: 0.8537 - val_f1_score: 0.8566 - relative: 54.9091\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1891 - accuracy: 0.9400 - f1_score: 0.9397 - val_loss: 0.9312 - val_accuracy: 0.7854 - val_f1_score: 0.7859 - relative: 55.8426\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2033 - accuracy: 0.9326 - f1_score: 0.9318 - val_loss: 0.5421 - val_accuracy: 0.8488 - val_f1_score: 0.8555 - relative: 56.7848\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1268 - accuracy: 0.9559 - f1_score: 0.9555 - val_loss: 0.5891 - val_accuracy: 0.8634 - val_f1_score: 0.8693 - relative: 57.7208\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0927 - accuracy: 0.9694 - f1_score: 0.9692 - val_loss: 0.6685 - val_accuracy: 0.8439 - val_f1_score: 0.8499 - relative: 58.6793\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0417 - accuracy: 0.9890 - f1_score: 0.9890 - val_loss: 0.6410 - val_accuracy: 0.8488 - val_f1_score: 0.8526 - relative: 59.6146\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0453 - accuracy: 0.9865 - f1_score: 0.9862 - val_loss: 0.6595 - val_accuracy: 0.8488 - val_f1_score: 0.8523 - relative: 60.5570\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0622 - accuracy: 0.9804 - f1_score: 0.9801 - val_loss: 0.6071 - val_accuracy: 0.8634 - val_f1_score: 0.8669 - relative: 61.4957\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.0476 - accuracy: 0.9841 - f1_score: 0.9838 - val_loss: 0.5076 - val_accuracy: 0.8878 - val_f1_score: 0.8893 - relative: 62.4421\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0806 - accuracy: 0.9755 - f1_score: 0.9752 - val_loss: 0.6178 - val_accuracy: 0.8585 - val_f1_score: 0.8574 - relative: 63.8670\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0672 - accuracy: 0.9828 - f1_score: 0.9825 - val_loss: 0.7683 - val_accuracy: 0.8390 - val_f1_score: 0.8419 - relative: 64.7862\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0881 - accuracy: 0.9743 - f1_score: 0.9737 - val_loss: 0.7934 - val_accuracy: 0.8146 - val_f1_score: 0.8169 - relative: 65.7158\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1199 - accuracy: 0.9571 - f1_score: 0.9561 - val_loss: 0.6453 - val_accuracy: 0.8341 - val_f1_score: 0.8394 - relative: 66.6737\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1152 - accuracy: 0.9645 - f1_score: 0.9640 - val_loss: 0.5707 - val_accuracy: 0.8683 - val_f1_score: 0.8708 - relative: 67.6175\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0642 - accuracy: 0.9779 - f1_score: 0.9778 - val_loss: 0.6084 - val_accuracy: 0.8488 - val_f1_score: 0.8554 - relative: 68.5361\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.1007 - accuracy: 0.9706 - f1_score: 0.9700 - val_loss: 0.7942 - val_accuracy: 0.8244 - val_f1_score: 0.8255 - relative: 69.5190\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0840 - accuracy: 0.9730 - f1_score: 0.9729 - val_loss: 0.6369 - val_accuracy: 0.8683 - val_f1_score: 0.8731 - relative: 70.4314\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1060 - accuracy: 0.9706 - f1_score: 0.9703 - val_loss: 0.7004 - val_accuracy: 0.8341 - val_f1_score: 0.8364 - relative: 71.3756\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0868 - accuracy: 0.9681 - f1_score: 0.9677 - val_loss: 0.6488 - val_accuracy: 0.8488 - val_f1_score: 0.8572 - relative: 72.3229\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0780 - accuracy: 0.9718 - f1_score: 0.9715 - val_loss: 0.7590 - val_accuracy: 0.8390 - val_f1_score: 0.8383 - relative: 73.2660\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0908 - accuracy: 0.9730 - f1_score: 0.9729 - val_loss: 0.5720 - val_accuracy: 0.8683 - val_f1_score: 0.8731 - relative: 74.1930\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1042 - accuracy: 0.9681 - f1_score: 0.9682 - val_loss: 0.8065 - val_accuracy: 0.8098 - val_f1_score: 0.8182 - relative: 75.1556\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1575 - accuracy: 0.9571 - f1_score: 0.9571 - val_loss: 0.8239 - val_accuracy: 0.8098 - val_f1_score: 0.8200 - relative: 76.1109\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1928 - accuracy: 0.9387 - f1_score: 0.9376 - val_loss: 0.6096 - val_accuracy: 0.8488 - val_f1_score: 0.8523 - relative: 77.0787\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1119 - accuracy: 0.9620 - f1_score: 0.9619 - val_loss: 0.5712 - val_accuracy: 0.8390 - val_f1_score: 0.8423 - relative: 78.0280\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0372 - accuracy: 0.9902 - f1_score: 0.9902 - val_loss: 0.6367 - val_accuracy: 0.8585 - val_f1_score: 0.8626 - relative: 78.9543\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0196 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.6929 - val_accuracy: 0.8537 - val_f1_score: 0.8584 - relative: 79.8776\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0226 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.7534 - val_accuracy: 0.8537 - val_f1_score: 0.8574 - relative: 80.8259\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0316 - accuracy: 0.9926 - f1_score: 0.9924 - val_loss: 0.7799 - val_accuracy: 0.8439 - val_f1_score: 0.8496 - relative: 81.7560\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0200 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.7134 - val_accuracy: 0.8634 - val_f1_score: 0.8672 - relative: 82.7355\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0158 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.7237 - val_accuracy: 0.8537 - val_f1_score: 0.8563 - relative: 83.6800\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0692 - accuracy: 0.9779 - f1_score: 0.9781 - val_loss: 0.6749 - val_accuracy: 0.8439 - val_f1_score: 0.8499 - relative: 84.6022\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0601 - accuracy: 0.9804 - f1_score: 0.9802 - val_loss: 0.5964 - val_accuracy: 0.8439 - val_f1_score: 0.8461 - relative: 85.5362\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0665 - accuracy: 0.9816 - f1_score: 0.9815 - val_loss: 0.6823 - val_accuracy: 0.8390 - val_f1_score: 0.8407 - relative: 86.4942\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0644 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.6671 - val_accuracy: 0.8488 - val_f1_score: 0.8529 - relative: 87.4059\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0620 - accuracy: 0.9804 - f1_score: 0.9802 - val_loss: 0.6917 - val_accuracy: 0.8439 - val_f1_score: 0.8491 - relative: 88.3355\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0969 - accuracy: 0.9755 - f1_score: 0.9750 - val_loss: 0.7483 - val_accuracy: 0.8341 - val_f1_score: 0.8389 - relative: 89.2786\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0735 - accuracy: 0.9718 - f1_score: 0.9712 - val_loss: 0.8240 - val_accuracy: 0.8390 - val_f1_score: 0.8424 - relative: 90.1972\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0957 - accuracy: 0.9706 - f1_score: 0.9699 - val_loss: 0.6828 - val_accuracy: 0.8439 - val_f1_score: 0.8458 - relative: 91.1413\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0481 - accuracy: 0.9877 - f1_score: 0.9876 - val_loss: 0.7836 - val_accuracy: 0.8488 - val_f1_score: 0.8514 - relative: 92.0767\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0420 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.7408 - val_accuracy: 0.8537 - val_f1_score: 0.8592 - relative: 93.0208\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0502 - accuracy: 0.9865 - f1_score: 0.9864 - val_loss: 0.6495 - val_accuracy: 0.8634 - val_f1_score: 0.8673 - relative: 93.9627\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0619 - accuracy: 0.9865 - f1_score: 0.9862 - val_loss: 0.7320 - val_accuracy: 0.8390 - val_f1_score: 0.8415 - relative: 94.9721\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.1068 - accuracy: 0.9792 - f1_score: 0.9785 - val_loss: 0.6507 - val_accuracy: 0.8439 - val_f1_score: 0.8484 - relative: 95.9846\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0446 - accuracy: 0.9877 - f1_score: 0.9874 - val_loss: 0.5646 - val_accuracy: 0.8585 - val_f1_score: 0.8640 - relative: 97.0063\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0255 - accuracy: 0.9926 - f1_score: 0.9927 - val_loss: 0.5976 - val_accuracy: 0.8585 - val_f1_score: 0.8672 - relative: 97.9381\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0276 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.6351 - val_accuracy: 0.8634 - val_f1_score: 0.8671 - relative: 98.8732\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0457 - accuracy: 0.9865 - f1_score: 0.9863 - val_loss: 0.6247 - val_accuracy: 0.8488 - val_f1_score: 0.8563 - relative: 99.8166\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0673 - accuracy: 0.9841 - f1_score: 0.9838 - val_loss: 0.6081 - val_accuracy: 0.8732 - val_f1_score: 0.8787 - relative: 100.7380\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0449 - accuracy: 0.9865 - f1_score: 0.9863 - val_loss: 0.6908 - val_accuracy: 0.8634 - val_f1_score: 0.8664 - relative: 101.6880\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0150 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.6670 - val_accuracy: 0.8683 - val_f1_score: 0.8735 - relative: 102.6319\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0161 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.7378 - val_accuracy: 0.8537 - val_f1_score: 0.8565 - relative: 103.5987\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0085 - accuracy: 0.9963 - f1_score: 0.9962 - val_loss: 0.6485 - val_accuracy: 0.8829 - val_f1_score: 0.8886 - relative: 104.5567\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0196 - accuracy: 0.9963 - f1_score: 0.9961 - val_loss: 0.7131 - val_accuracy: 0.8634 - val_f1_score: 0.8670 - relative: 105.5142\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0529 - accuracy: 0.9828 - f1_score: 0.9824 - val_loss: 0.8504 - val_accuracy: 0.8488 - val_f1_score: 0.8530 - relative: 106.4644\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0865 - accuracy: 0.9792 - f1_score: 0.9785 - val_loss: 0.7009 - val_accuracy: 0.8439 - val_f1_score: 0.8449 - relative: 107.4208\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0372 - accuracy: 0.9890 - f1_score: 0.9888 - val_loss: 0.7508 - val_accuracy: 0.8390 - val_f1_score: 0.8425 - relative: 108.3554\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0174 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.8309 - val_accuracy: 0.8488 - val_f1_score: 0.8528 - relative: 109.2801\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0422 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.8750 - val_accuracy: 0.8341 - val_f1_score: 0.8400 - relative: 110.2106\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1159 - accuracy: 0.9681 - f1_score: 0.9679 - val_loss: 0.6360 - val_accuracy: 0.8585 - val_f1_score: 0.8606 - relative: 111.1787\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0719 - accuracy: 0.9755 - f1_score: 0.9754 - val_loss: 0.6360 - val_accuracy: 0.8683 - val_f1_score: 0.8712 - relative: 112.1111\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1079 - accuracy: 0.9681 - f1_score: 0.9680 - val_loss: 0.6545 - val_accuracy: 0.8439 - val_f1_score: 0.8451 - relative: 113.0477\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0649 - accuracy: 0.9767 - f1_score: 0.9767 - val_loss: 0.3770 - val_accuracy: 0.8927 - val_f1_score: 0.8955 - relative: 113.9919\n",
      "Epoch 95/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1177 - accuracy: 0.9804 - f1_score: 0.9804 - val_loss: 0.6048 - val_accuracy: 0.8439 - val_f1_score: 0.8554 - relative: 115.5977\n",
      "Epoch 96/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0755 - accuracy: 0.9755 - f1_score: 0.9754 - val_loss: 0.6927 - val_accuracy: 0.8341 - val_f1_score: 0.8431 - relative: 116.5310\n",
      "Epoch 97/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0943 - accuracy: 0.9743 - f1_score: 0.9738 - val_loss: 0.5089 - val_accuracy: 0.8585 - val_f1_score: 0.8616 - relative: 117.5221\n",
      "Epoch 98/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0666 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.5922 - val_accuracy: 0.8683 - val_f1_score: 0.8730 - relative: 118.4607\n",
      "Epoch 99/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0816 - accuracy: 0.9767 - f1_score: 0.9764 - val_loss: 0.7692 - val_accuracy: 0.8341 - val_f1_score: 0.8367 - relative: 119.3927\n",
      "Epoch 100/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1918 - accuracy: 0.9473 - f1_score: 0.9470 - val_loss: 0.5533 - val_accuracy: 0.8488 - val_f1_score: 0.8536 - relative: 120.3389\n",
      "Epoch 101/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1248 - accuracy: 0.9620 - f1_score: 0.9615 - val_loss: 0.8274 - val_accuracy: 0.8098 - val_f1_score: 0.8150 - relative: 121.2630\n",
      "Epoch 102/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1605 - accuracy: 0.9534 - f1_score: 0.9528 - val_loss: 0.6487 - val_accuracy: 0.8488 - val_f1_score: 0.8571 - relative: 122.2256\n",
      "Epoch 103/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1385 - accuracy: 0.9571 - f1_score: 0.9562 - val_loss: 0.8571 - val_accuracy: 0.8049 - val_f1_score: 0.8102 - relative: 123.1644\n",
      "Epoch 104/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1365 - accuracy: 0.9547 - f1_score: 0.9538 - val_loss: 0.4448 - val_accuracy: 0.8878 - val_f1_score: 0.8924 - relative: 124.1139\n",
      "Epoch 105/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0948 - accuracy: 0.9681 - f1_score: 0.9675 - val_loss: 0.6014 - val_accuracy: 0.8634 - val_f1_score: 0.8661 - relative: 125.0707\n",
      "Epoch 106/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0460 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.4897 - val_accuracy: 0.8829 - val_f1_score: 0.8876 - relative: 126.0116\n",
      "Epoch 107/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0192 - accuracy: 0.9939 - f1_score: 0.9938 - val_loss: 0.5748 - val_accuracy: 0.8829 - val_f1_score: 0.8884 - relative: 126.9364\n",
      "Epoch 108/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0105 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.5641 - val_accuracy: 0.8634 - val_f1_score: 0.8699 - relative: 127.8539\n",
      "Epoch 109/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0035 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.8683 - val_f1_score: 0.8749 - relative: 128.7613\n",
      "Epoch 110/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0034 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.5640 - val_accuracy: 0.8683 - val_f1_score: 0.8749 - relative: 129.6903\n",
      "Epoch 111/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.8683 - val_f1_score: 0.8749 - relative: 130.6266\n",
      "Epoch 112/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8683 - val_f1_score: 0.8746 - relative: 131.5859\n",
      "Epoch 113/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.9240e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8683 - val_f1_score: 0.8749 - relative: 132.5286\n",
      "Epoch 114/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 7.4781e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 7.4727e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.6048 - val_accuracy: 0.8683 - val_f1_score: 0.8749 - relative: 133.4411\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_lstm_dset1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_lstm_dset1', history)\n",
    "model.save('models/lstm_dset1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 34, 1024)         8908800   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 34, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,208,521\n",
      "Trainable params: 12,208,009\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bilstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 14s 174ms/step - loss: 1.6211 - accuracy: 0.4338 - f1_score: 0.4138 - val_loss: 1.6277 - val_accuracy: 0.5268 - val_f1_score: 0.5053 - relative: 13.8776\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 1.0340 - accuracy: 0.6446 - f1_score: 0.6278 - val_loss: 1.3097 - val_accuracy: 0.5854 - val_f1_score: 0.5749 - relative: 15.7443\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.7572 - accuracy: 0.7341 - f1_score: 0.7232 - val_loss: 1.0835 - val_accuracy: 0.7073 - val_f1_score: 0.7078 - relative: 18.0683\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.6043 - accuracy: 0.7978 - f1_score: 0.7916 - val_loss: 0.9213 - val_accuracy: 0.7122 - val_f1_score: 0.7121 - relative: 20.5283\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.4792 - accuracy: 0.8444 - f1_score: 0.8406 - val_loss: 0.8121 - val_accuracy: 0.6878 - val_f1_score: 0.6969 - relative: 22.8253\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.4200 - accuracy: 0.8529 - f1_score: 0.8490 - val_loss: 0.6254 - val_accuracy: 0.8098 - val_f1_score: 0.8124 - relative: 24.4688\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.3898 - accuracy: 0.8603 - f1_score: 0.8582 - val_loss: 0.6035 - val_accuracy: 0.7951 - val_f1_score: 0.8035 - relative: 26.7543\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.3692 - accuracy: 0.8725 - f1_score: 0.8707 - val_loss: 0.6771 - val_accuracy: 0.7659 - val_f1_score: 0.7712 - relative: 28.4135\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.3380 - accuracy: 0.8824 - f1_score: 0.8812 - val_loss: 0.6219 - val_accuracy: 0.7951 - val_f1_score: 0.7915 - relative: 30.0283\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.2764 - accuracy: 0.9056 - f1_score: 0.9039 - val_loss: 0.5827 - val_accuracy: 0.7805 - val_f1_score: 0.7875 - relative: 31.6354\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.2745 - accuracy: 0.9105 - f1_score: 0.9088 - val_loss: 0.5853 - val_accuracy: 0.8146 - val_f1_score: 0.8225 - relative: 33.2555\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 2s 97ms/step - loss: 0.1949 - accuracy: 0.9326 - f1_score: 0.9315 - val_loss: 0.5646 - val_accuracy: 0.8244 - val_f1_score: 0.8293 - relative: 35.5424\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.1761 - accuracy: 0.9424 - f1_score: 0.9418 - val_loss: 0.5644 - val_accuracy: 0.8293 - val_f1_score: 0.8329 - relative: 38.0472\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1799 - accuracy: 0.9436 - f1_score: 0.9433 - val_loss: 0.5276 - val_accuracy: 0.8244 - val_f1_score: 0.8259 - relative: 40.3654\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.1631 - accuracy: 0.9498 - f1_score: 0.9492 - val_loss: 0.4249 - val_accuracy: 0.8732 - val_f1_score: 0.8784 - relative: 41.9732\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1240 - accuracy: 0.9596 - f1_score: 0.9591 - val_loss: 0.6363 - val_accuracy: 0.8341 - val_f1_score: 0.8366 - relative: 44.3129\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.1594 - accuracy: 0.9461 - f1_score: 0.9450 - val_loss: 0.4559 - val_accuracy: 0.8634 - val_f1_score: 0.8659 - relative: 45.9295\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1507 - accuracy: 0.9645 - f1_score: 0.9640 - val_loss: 0.4488 - val_accuracy: 0.8683 - val_f1_score: 0.8690 - relative: 47.5724\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0955 - accuracy: 0.9669 - f1_score: 0.9664 - val_loss: 0.5083 - val_accuracy: 0.8732 - val_f1_score: 0.8747 - relative: 49.2350\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0876 - accuracy: 0.9694 - f1_score: 0.9690 - val_loss: 0.4324 - val_accuracy: 0.8634 - val_f1_score: 0.8667 - relative: 50.8875\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0638 - accuracy: 0.9755 - f1_score: 0.9752 - val_loss: 0.4967 - val_accuracy: 0.8634 - val_f1_score: 0.8661 - relative: 52.5805\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1151 - accuracy: 0.9681 - f1_score: 0.9679 - val_loss: 0.4290 - val_accuracy: 0.8683 - val_f1_score: 0.8706 - relative: 54.2417\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1513 - accuracy: 0.9498 - f1_score: 0.9489 - val_loss: 0.5483 - val_accuracy: 0.8585 - val_f1_score: 0.8606 - relative: 55.8966\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1977 - accuracy: 0.9424 - f1_score: 0.9411 - val_loss: 0.4527 - val_accuracy: 0.8488 - val_f1_score: 0.8572 - relative: 57.5380\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1357 - accuracy: 0.9571 - f1_score: 0.9567 - val_loss: 0.4183 - val_accuracy: 0.8585 - val_f1_score: 0.8667 - relative: 59.2060\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.1135 - accuracy: 0.9694 - f1_score: 0.9690 - val_loss: 0.3223 - val_accuracy: 0.8976 - val_f1_score: 0.8998 - relative: 60.8768\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.0724 - accuracy: 0.9730 - f1_score: 0.9727 - val_loss: 0.3330 - val_accuracy: 0.9024 - val_f1_score: 0.9071 - relative: 63.2004\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.0670 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.5306 - val_accuracy: 0.8488 - val_f1_score: 0.8539 - relative: 65.7244\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0742 - accuracy: 0.9792 - f1_score: 0.9788 - val_loss: 0.4537 - val_accuracy: 0.8829 - val_f1_score: 0.8842 - relative: 67.3757\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0804 - accuracy: 0.9743 - f1_score: 0.9740 - val_loss: 0.4401 - val_accuracy: 0.8829 - val_f1_score: 0.8872 - relative: 69.0854\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.1043 - accuracy: 0.9669 - f1_score: 0.9665 - val_loss: 0.4696 - val_accuracy: 0.8732 - val_f1_score: 0.8779 - relative: 70.7752\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0602 - accuracy: 0.9853 - f1_score: 0.9851 - val_loss: 0.5483 - val_accuracy: 0.8390 - val_f1_score: 0.8460 - relative: 72.4700\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0621 - accuracy: 0.9841 - f1_score: 0.9838 - val_loss: 0.3696 - val_accuracy: 0.8780 - val_f1_score: 0.8857 - relative: 74.1621\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0639 - accuracy: 0.9792 - f1_score: 0.9789 - val_loss: 0.6599 - val_accuracy: 0.8537 - val_f1_score: 0.8582 - relative: 75.8518\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0740 - accuracy: 0.9792 - f1_score: 0.9791 - val_loss: 0.6180 - val_accuracy: 0.8439 - val_f1_score: 0.8486 - relative: 77.5228\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1268 - accuracy: 0.9669 - f1_score: 0.9667 - val_loss: 0.5581 - val_accuracy: 0.8341 - val_f1_score: 0.8376 - relative: 79.1815\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.1456 - accuracy: 0.9608 - f1_score: 0.9600 - val_loss: 0.6079 - val_accuracy: 0.8390 - val_f1_score: 0.8426 - relative: 80.7918\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0995 - accuracy: 0.9669 - f1_score: 0.9662 - val_loss: 0.5140 - val_accuracy: 0.8683 - val_f1_score: 0.8707 - relative: 82.4644\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0954 - accuracy: 0.9755 - f1_score: 0.9752 - val_loss: 0.5835 - val_accuracy: 0.8634 - val_f1_score: 0.8680 - relative: 84.1405\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0319 - accuracy: 0.9877 - f1_score: 0.9876 - val_loss: 0.6208 - val_accuracy: 0.8488 - val_f1_score: 0.8542 - relative: 85.7887\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0383 - accuracy: 0.9877 - f1_score: 0.9877 - val_loss: 0.5965 - val_accuracy: 0.8634 - val_f1_score: 0.8664 - relative: 87.4408\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0506 - accuracy: 0.9816 - f1_score: 0.9816 - val_loss: 0.4633 - val_accuracy: 0.8878 - val_f1_score: 0.8914 - relative: 89.0896\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0275 - accuracy: 0.9926 - f1_score: 0.9927 - val_loss: 0.4802 - val_accuracy: 0.8976 - val_f1_score: 0.8985 - relative: 90.7463\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0330 - accuracy: 0.9926 - f1_score: 0.9927 - val_loss: 0.5497 - val_accuracy: 0.8780 - val_f1_score: 0.8822 - relative: 92.4342\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0250 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.5114 - val_accuracy: 0.8780 - val_f1_score: 0.8791 - relative: 94.0918\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0314 - accuracy: 0.9914 - f1_score: 0.9912 - val_loss: 0.5232 - val_accuracy: 0.8732 - val_f1_score: 0.8758 - relative: 95.7789\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0343 - accuracy: 0.9865 - f1_score: 0.9864 - val_loss: 0.5150 - val_accuracy: 0.8780 - val_f1_score: 0.8826 - relative: 97.4220\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0206 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.5643 - val_accuracy: 0.8732 - val_f1_score: 0.8789 - relative: 99.0722\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0080 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.5728 - val_accuracy: 0.8634 - val_f1_score: 0.8677 - relative: 100.7350\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0055 - accuracy: 0.9975 - f1_score: 0.9976 - val_loss: 0.5920 - val_accuracy: 0.8732 - val_f1_score: 0.8763 - relative: 102.4410\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.0329 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.4458 - val_accuracy: 0.9073 - val_f1_score: 0.9115 - relative: 104.1028\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0087 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.6597 - val_accuracy: 0.8683 - val_f1_score: 0.8755 - relative: 106.4818\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0170 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.5814 - val_accuracy: 0.8780 - val_f1_score: 0.8832 - relative: 108.1320\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0034 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.8585 - val_f1_score: 0.8628 - relative: 109.8215\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0018 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.8488 - val_f1_score: 0.8531 - relative: 111.4734\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0010 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.8634 - val_f1_score: 0.8674 - relative: 113.1782\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 7.2042e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.8829 - val_f1_score: 0.8862 - relative: 114.8413\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 5.0991e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.8878 - val_f1_score: 0.8910 - relative: 116.5113\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 3.6711e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8829 - val_f1_score: 0.8859 - relative: 118.2063\n",
      "Epoch 60/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 3.4859e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 4.0703e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8829 - val_f1_score: 0.8859 - relative: 119.8893\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_bilstm_dset1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_bilstm_dset1', history)\n",
    "model.save('models/bilstm_dset1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2\n",
    "Component: Mouth, Body, Right Hand, and Left Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets2.h5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    x_val = np.array(hf.get('x_val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 34, 512)           1824768   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 34, 256)           787456    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,820,489\n",
      "Trainable params: 2,820,233\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 11s 87ms/step - loss: 1.2811 - accuracy: 0.5551 - f1_score: 0.5407 - val_loss: 1.1597 - val_accuracy: 0.7220 - val_f1_score: 0.7215 - relative: 11.3592\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.4578 - accuracy: 0.8664 - f1_score: 0.8647 - val_loss: 0.7387 - val_accuracy: 0.8390 - val_f1_score: 0.8475 - relative: 12.2456\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.2317 - accuracy: 0.9289 - f1_score: 0.9284 - val_loss: 0.4006 - val_accuracy: 0.9366 - val_f1_score: 0.9395 - relative: 13.3869\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2053 - accuracy: 0.9375 - f1_score: 0.9374 - val_loss: 0.4049 - val_accuracy: 0.8878 - val_f1_score: 0.8897 - relative: 14.5442\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1750 - accuracy: 0.9473 - f1_score: 0.9469 - val_loss: 0.3435 - val_accuracy: 0.8976 - val_f1_score: 0.9042 - relative: 15.3270\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.1629 - accuracy: 0.9461 - f1_score: 0.9455 - val_loss: 0.2998 - val_accuracy: 0.9073 - val_f1_score: 0.9103 - relative: 16.1558\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1771 - accuracy: 0.9473 - f1_score: 0.9469 - val_loss: 0.2738 - val_accuracy: 0.9220 - val_f1_score: 0.9265 - relative: 16.9266\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1341 - accuracy: 0.9583 - f1_score: 0.9579 - val_loss: 0.2276 - val_accuracy: 0.9415 - val_f1_score: 0.9447 - relative: 17.7430\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.1039 - accuracy: 0.9694 - f1_score: 0.9688 - val_loss: 0.1644 - val_accuracy: 0.9512 - val_f1_score: 0.9530 - relative: 18.9262\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1342 - accuracy: 0.9645 - f1_score: 0.9643 - val_loss: 0.3331 - val_accuracy: 0.9073 - val_f1_score: 0.9117 - relative: 20.0913\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1040 - accuracy: 0.9706 - f1_score: 0.9706 - val_loss: 0.2578 - val_accuracy: 0.9122 - val_f1_score: 0.9149 - relative: 20.8723\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0847 - accuracy: 0.9669 - f1_score: 0.9667 - val_loss: 0.1974 - val_accuracy: 0.9415 - val_f1_score: 0.9446 - relative: 21.6479\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.1000 - accuracy: 0.9681 - f1_score: 0.9683 - val_loss: 0.1693 - val_accuracy: 0.9561 - val_f1_score: 0.9574 - relative: 22.4334\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.0557 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.1291 - val_accuracy: 0.9659 - val_f1_score: 0.9685 - relative: 23.7483\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0743 - accuracy: 0.9792 - f1_score: 0.9788 - val_loss: 0.3894 - val_accuracy: 0.9171 - val_f1_score: 0.9203 - relative: 25.1130\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.1269 - accuracy: 0.9632 - f1_score: 0.9629 - val_loss: 0.1989 - val_accuracy: 0.9415 - val_f1_score: 0.9439 - relative: 25.9377\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0540 - accuracy: 0.9828 - f1_score: 0.9825 - val_loss: 0.2996 - val_accuracy: 0.9317 - val_f1_score: 0.9363 - relative: 26.7539\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0337 - accuracy: 0.9890 - f1_score: 0.9888 - val_loss: 0.2147 - val_accuracy: 0.9317 - val_f1_score: 0.9323 - relative: 27.5575\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0155 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.1692 - val_accuracy: 0.9463 - val_f1_score: 0.9499 - relative: 28.3999\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0073 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.1568 - val_accuracy: 0.9463 - val_f1_score: 0.9503 - relative: 29.1903\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0066 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.1766 - val_accuracy: 0.9512 - val_f1_score: 0.9551 - relative: 29.9591\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0091 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.2628 - val_accuracy: 0.9415 - val_f1_score: 0.9460 - relative: 30.7514\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0058 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.2270 - val_accuracy: 0.9463 - val_f1_score: 0.9504 - relative: 31.5734\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9463 - val_f1_score: 0.9504 - relative: 32.3560\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9463 - val_f1_score: 0.9504 - relative: 33.1245\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0099 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.2199 - val_accuracy: 0.9512 - val_f1_score: 0.9548 - relative: 33.9004\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0032 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.2819 - val_accuracy: 0.9463 - val_f1_score: 0.9504 - relative: 34.7095\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0243 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.2292 - val_accuracy: 0.9561 - val_f1_score: 0.9593 - relative: 35.5265\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0844 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.1250 - val_accuracy: 0.9610 - val_f1_score: 0.9636 - relative: 36.3094\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0664 - accuracy: 0.9779 - f1_score: 0.9776 - val_loss: 0.2236 - val_accuracy: 0.9561 - val_f1_score: 0.9581 - relative: 37.0878\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1274 - accuracy: 0.9718 - f1_score: 0.9716 - val_loss: 0.2303 - val_accuracy: 0.9366 - val_f1_score: 0.9399 - relative: 37.8846\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0618 - accuracy: 0.9730 - f1_score: 0.9727 - val_loss: 0.2897 - val_accuracy: 0.9415 - val_f1_score: 0.9459 - relative: 38.7028\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0596 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.3188 - val_accuracy: 0.9317 - val_f1_score: 0.9345 - relative: 39.4809\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0960 - accuracy: 0.9730 - f1_score: 0.9728 - val_loss: 0.1943 - val_accuracy: 0.9512 - val_f1_score: 0.9540 - relative: 40.2817\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0812 - accuracy: 0.9792 - f1_score: 0.9790 - val_loss: 0.2001 - val_accuracy: 0.9415 - val_f1_score: 0.9440 - relative: 41.0830\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0862 - accuracy: 0.9779 - f1_score: 0.9779 - val_loss: 0.2610 - val_accuracy: 0.9220 - val_f1_score: 0.9261 - relative: 41.8896\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0703 - accuracy: 0.9804 - f1_score: 0.9804 - val_loss: 0.2895 - val_accuracy: 0.9366 - val_f1_score: 0.9392 - relative: 42.6967\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1132 - accuracy: 0.9657 - f1_score: 0.9657 - val_loss: 0.3171 - val_accuracy: 0.9024 - val_f1_score: 0.9022 - relative: 43.4495\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0862 - accuracy: 0.9792 - f1_score: 0.9792 - val_loss: 0.2110 - val_accuracy: 0.9512 - val_f1_score: 0.9548 - relative: 44.2500\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0867 - accuracy: 0.9804 - f1_score: 0.9803 - val_loss: 0.3131 - val_accuracy: 0.9463 - val_f1_score: 0.9495 - relative: 45.0728\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0684 - accuracy: 0.9865 - f1_score: 0.9863 - val_loss: 0.2135 - val_accuracy: 0.9561 - val_f1_score: 0.9587 - relative: 45.8997\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0181 - accuracy: 0.9975 - f1_score: 0.9976 - val_loss: 0.1950 - val_accuracy: 0.9561 - val_f1_score: 0.9596 - relative: 46.6977\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1770 - val_accuracy: 0.9659 - val_f1_score: 0.9686 - relative: 47.5039\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0089 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1851 - val_accuracy: 0.9659 - val_f1_score: 0.9689 - relative: 48.3191\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0094 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1837 - val_accuracy: 0.9610 - val_f1_score: 0.9640 - relative: 49.0979\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0078 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1970 - val_accuracy: 0.9610 - val_f1_score: 0.9642 - relative: 49.9189\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 50.7237\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 51.5345\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_lstm_dset2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_lstm_dset2', history)\n",
    "model.save('models/lstm_dset2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 34, 1024)         3649536   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 34, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,949,257\n",
      "Trainable params: 6,948,745\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bilstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 13s 152ms/step - loss: 1.0998 - accuracy: 0.6532 - f1_score: 0.6385 - val_loss: 0.8975 - val_accuracy: 0.8732 - val_f1_score: 0.8791 - relative: 13.0617\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.2971 - accuracy: 0.8958 - f1_score: 0.8954 - val_loss: 0.5691 - val_accuracy: 0.8585 - val_f1_score: 0.8633 - relative: 14.5499\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.2077 - accuracy: 0.9338 - f1_score: 0.9332 - val_loss: 0.4401 - val_accuracy: 0.9024 - val_f1_score: 0.9046 - relative: 15.9264\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.1345 - accuracy: 0.9498 - f1_score: 0.9496 - val_loss: 0.3498 - val_accuracy: 0.8878 - val_f1_score: 0.8901 - relative: 18.2107\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.1255 - accuracy: 0.9559 - f1_score: 0.9558 - val_loss: 0.3016 - val_accuracy: 0.9073 - val_f1_score: 0.9113 - relative: 19.5712\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.1292 - accuracy: 0.9583 - f1_score: 0.9580 - val_loss: 0.2512 - val_accuracy: 0.9122 - val_f1_score: 0.9163 - relative: 21.6940\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.1673 - accuracy: 0.9449 - f1_score: 0.9438 - val_loss: 0.2584 - val_accuracy: 0.9073 - val_f1_score: 0.9132 - relative: 23.6956\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.1024 - accuracy: 0.9694 - f1_score: 0.9692 - val_loss: 0.2397 - val_accuracy: 0.9171 - val_f1_score: 0.9197 - relative: 25.0628\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.0596 - accuracy: 0.9816 - f1_score: 0.9814 - val_loss: 0.1365 - val_accuracy: 0.9463 - val_f1_score: 0.9493 - relative: 27.3168\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.0612 - accuracy: 0.9841 - f1_score: 0.9839 - val_loss: 0.1662 - val_accuracy: 0.9512 - val_f1_score: 0.9545 - relative: 29.4783\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0289 - accuracy: 0.9902 - f1_score: 0.9902 - val_loss: 0.2053 - val_accuracy: 0.9366 - val_f1_score: 0.9377 - relative: 31.4932\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0326 - accuracy: 0.9902 - f1_score: 0.9903 - val_loss: 0.2466 - val_accuracy: 0.9366 - val_f1_score: 0.9409 - relative: 32.8513\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.0323 - accuracy: 0.9939 - f1_score: 0.9938 - val_loss: 0.1375 - val_accuracy: 0.9610 - val_f1_score: 0.9636 - relative: 34.2480\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0199 - accuracy: 0.9939 - f1_score: 0.9938 - val_loss: 0.1900 - val_accuracy: 0.9561 - val_f1_score: 0.9597 - relative: 36.4909\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0044 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9561 - val_f1_score: 0.9593 - relative: 37.8253\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.0114 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1006 - val_accuracy: 0.9707 - val_f1_score: 0.9729 - relative: 39.1715\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0301 - accuracy: 0.9902 - f1_score: 0.9901 - val_loss: 0.1866 - val_accuracy: 0.9512 - val_f1_score: 0.9549 - relative: 41.2652\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0832 - accuracy: 0.9743 - f1_score: 0.9738 - val_loss: 0.2055 - val_accuracy: 0.9463 - val_f1_score: 0.9488 - relative: 42.5820\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0381 - accuracy: 0.9914 - f1_score: 0.9914 - val_loss: 0.2118 - val_accuracy: 0.9561 - val_f1_score: 0.9592 - relative: 43.9136\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0496 - accuracy: 0.9865 - f1_score: 0.9864 - val_loss: 0.2133 - val_accuracy: 0.9366 - val_f1_score: 0.9398 - relative: 45.2693\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0305 - accuracy: 0.9877 - f1_score: 0.9875 - val_loss: 0.1848 - val_accuracy: 0.9659 - val_f1_score: 0.9681 - relative: 46.5751\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0317 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.2429 - val_accuracy: 0.9512 - val_f1_score: 0.9536 - relative: 47.9164\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0248 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.2197 - val_accuracy: 0.9512 - val_f1_score: 0.9545 - relative: 49.2363\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0136 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.2087 - val_accuracy: 0.9561 - val_f1_score: 0.9596 - relative: 50.6079\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0067 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.1589 - val_accuracy: 0.9659 - val_f1_score: 0.9688 - relative: 51.9600\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0119 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.1999 - val_accuracy: 0.9610 - val_f1_score: 0.9635 - relative: 53.3055\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0103 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.2653 - val_accuracy: 0.9512 - val_f1_score: 0.9554 - relative: 54.6740\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0089 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.2130 - val_accuracy: 0.9610 - val_f1_score: 0.9640 - relative: 56.0088\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9610 - val_f1_score: 0.9637 - relative: 57.3840\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 9.6561e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9610 - val_f1_score: 0.9637 - relative: 58.7421\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 4.0208e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 60.0877\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 3.6112e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 61.4282\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 4.2064e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 62.7929\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 2.8478e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 64.1853\n",
      "Epoch 35/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 2.4408e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 2.4482e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 65.5535\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_bilstm_dset2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_bilstm_dset2', history)\n",
    "model.save('models/bilstm_dset2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3\n",
    "Component: Face, Upper Body, Right Hand, and Left Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets3.h5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    x_val = np.array(hf.get('x_val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 34, 512)           4388864   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 34, 256)           787456    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,384,585\n",
      "Trainable params: 5,384,329\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 5/26 [====>.........................] - ETA: 0s - loss: 2.0733 - accuracy: 0.3187 - f1_score: 0.2734 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0258s vs `on_train_batch_end` time: 0.0269s). Check your callbacks.\n",
      "26/26 [==============================] - 7s 93ms/step - loss: 1.5482 - accuracy: 0.4645 - f1_score: 0.4202 - val_loss: 1.6450 - val_accuracy: 0.5659 - val_f1_score: 0.5491 - relative: 7.6512\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.9786 - accuracy: 0.6532 - f1_score: 0.6354 - val_loss: 1.3825 - val_accuracy: 0.5951 - val_f1_score: 0.5919 - relative: 8.7283\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.7585 - accuracy: 0.7390 - f1_score: 0.7337 - val_loss: 1.0604 - val_accuracy: 0.6878 - val_f1_score: 0.6966 - relative: 10.1542\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6560 - accuracy: 0.7635 - f1_score: 0.7574 - val_loss: 0.9529 - val_accuracy: 0.6634 - val_f1_score: 0.6698 - relative: 11.5833\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.5629 - accuracy: 0.8002 - f1_score: 0.7978 - val_loss: 0.8508 - val_accuracy: 0.7073 - val_f1_score: 0.7114 - relative: 12.5470\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.5235 - accuracy: 0.8248 - f1_score: 0.8214 - val_loss: 0.8062 - val_accuracy: 0.7122 - val_f1_score: 0.7107 - relative: 13.9211\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.4411 - accuracy: 0.8554 - f1_score: 0.8538 - val_loss: 0.7498 - val_accuracy: 0.7415 - val_f1_score: 0.7407 - relative: 15.3065\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.4346 - accuracy: 0.8529 - f1_score: 0.8510 - val_loss: 0.6539 - val_accuracy: 0.7415 - val_f1_score: 0.7459 - relative: 16.8192\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.3981 - accuracy: 0.8713 - f1_score: 0.8709 - val_loss: 0.5867 - val_accuracy: 0.7805 - val_f1_score: 0.7834 - relative: 17.7915\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.3329 - accuracy: 0.8836 - f1_score: 0.8829 - val_loss: 0.3880 - val_accuracy: 0.8390 - val_f1_score: 0.8439 - relative: 19.2353\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.2790 - accuracy: 0.9105 - f1_score: 0.9092 - val_loss: 0.6488 - val_accuracy: 0.7707 - val_f1_score: 0.7749 - relative: 20.6343\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.3610 - accuracy: 0.8787 - f1_score: 0.8774 - val_loss: 0.6504 - val_accuracy: 0.7756 - val_f1_score: 0.7733 - relative: 21.5543\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.2703 - accuracy: 0.8983 - f1_score: 0.8967 - val_loss: 0.4178 - val_accuracy: 0.8585 - val_f1_score: 0.8654 - relative: 22.4956\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2257 - accuracy: 0.9289 - f1_score: 0.9276 - val_loss: 0.7967 - val_accuracy: 0.7512 - val_f1_score: 0.7524 - relative: 23.8286\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.3057 - accuracy: 0.8909 - f1_score: 0.8888 - val_loss: 0.5906 - val_accuracy: 0.7902 - val_f1_score: 0.7901 - relative: 24.7978\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2589 - accuracy: 0.9020 - f1_score: 0.9011 - val_loss: 0.5134 - val_accuracy: 0.8049 - val_f1_score: 0.8070 - relative: 25.7279\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1763 - accuracy: 0.9350 - f1_score: 0.9343 - val_loss: 0.5878 - val_accuracy: 0.8439 - val_f1_score: 0.8490 - relative: 26.6870\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1955 - accuracy: 0.9326 - f1_score: 0.9320 - val_loss: 0.5173 - val_accuracy: 0.8293 - val_f1_score: 0.8372 - relative: 27.6194\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1249 - accuracy: 0.9559 - f1_score: 0.9552 - val_loss: 0.6189 - val_accuracy: 0.8146 - val_f1_score: 0.8198 - relative: 28.5593\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1415 - accuracy: 0.9608 - f1_score: 0.9603 - val_loss: 0.6914 - val_accuracy: 0.8244 - val_f1_score: 0.8279 - relative: 29.4927\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.1637 - accuracy: 0.9559 - f1_score: 0.9549 - val_loss: 0.4366 - val_accuracy: 0.8878 - val_f1_score: 0.8913 - relative: 30.4195\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1152 - accuracy: 0.9681 - f1_score: 0.9678 - val_loss: 0.4886 - val_accuracy: 0.8585 - val_f1_score: 0.8616 - relative: 31.8251\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1528 - accuracy: 0.9547 - f1_score: 0.9545 - val_loss: 0.4875 - val_accuracy: 0.8390 - val_f1_score: 0.8400 - relative: 32.7561\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1312 - accuracy: 0.9571 - f1_score: 0.9568 - val_loss: 0.4665 - val_accuracy: 0.8537 - val_f1_score: 0.8604 - relative: 33.6793\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1026 - accuracy: 0.9608 - f1_score: 0.9606 - val_loss: 0.6255 - val_accuracy: 0.8488 - val_f1_score: 0.8527 - relative: 34.5918\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1861 - accuracy: 0.9424 - f1_score: 0.9421 - val_loss: 0.6920 - val_accuracy: 0.8098 - val_f1_score: 0.8106 - relative: 35.5423\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2061 - accuracy: 0.9338 - f1_score: 0.9338 - val_loss: 0.7543 - val_accuracy: 0.7854 - val_f1_score: 0.7849 - relative: 36.4702\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1908 - accuracy: 0.9424 - f1_score: 0.9421 - val_loss: 0.5026 - val_accuracy: 0.8634 - val_f1_score: 0.8688 - relative: 37.3995\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1515 - accuracy: 0.9547 - f1_score: 0.9541 - val_loss: 0.4782 - val_accuracy: 0.8732 - val_f1_score: 0.8764 - relative: 38.3346\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0760 - accuracy: 0.9755 - f1_score: 0.9754 - val_loss: 0.5670 - val_accuracy: 0.8585 - val_f1_score: 0.8627 - relative: 39.2970\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1747 - accuracy: 0.9400 - f1_score: 0.9383 - val_loss: 0.5137 - val_accuracy: 0.8390 - val_f1_score: 0.8392 - relative: 40.2170\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.2003 - accuracy: 0.9326 - f1_score: 0.9314 - val_loss: 0.4455 - val_accuracy: 0.8683 - val_f1_score: 0.8708 - relative: 41.1485\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1837 - accuracy: 0.9461 - f1_score: 0.9457 - val_loss: 0.4771 - val_accuracy: 0.8683 - val_f1_score: 0.8690 - relative: 42.0927\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1316 - accuracy: 0.9596 - f1_score: 0.9585 - val_loss: 0.4405 - val_accuracy: 0.8780 - val_f1_score: 0.8784 - relative: 43.0204\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0940 - accuracy: 0.9730 - f1_score: 0.9726 - val_loss: 0.4458 - val_accuracy: 0.8976 - val_f1_score: 0.8978 - relative: 43.9633\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0651 - accuracy: 0.9755 - f1_score: 0.9752 - val_loss: 0.4545 - val_accuracy: 0.8927 - val_f1_score: 0.8940 - relative: 45.3015\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0970 - accuracy: 0.9706 - f1_score: 0.9703 - val_loss: 0.5196 - val_accuracy: 0.8683 - val_f1_score: 0.8679 - relative: 46.2574\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0834 - accuracy: 0.9804 - f1_score: 0.9801 - val_loss: 0.4157 - val_accuracy: 0.8829 - val_f1_score: 0.8838 - relative: 47.1865\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0388 - accuracy: 0.9890 - f1_score: 0.9886 - val_loss: 0.3862 - val_accuracy: 0.8927 - val_f1_score: 0.8968 - relative: 48.1123\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0379 - accuracy: 0.9841 - f1_score: 0.9837 - val_loss: 0.4477 - val_accuracy: 0.8976 - val_f1_score: 0.8994 - relative: 49.0767\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0655 - accuracy: 0.9828 - f1_score: 0.9827 - val_loss: 0.4967 - val_accuracy: 0.8878 - val_f1_score: 0.8896 - relative: 50.0649\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.0285 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.5319 - val_accuracy: 0.8878 - val_f1_score: 0.8893 - relative: 51.0649\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0352 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.4728 - val_accuracy: 0.8976 - val_f1_score: 0.8995 - relative: 52.0225\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0380 - accuracy: 0.9877 - f1_score: 0.9877 - val_loss: 0.5680 - val_accuracy: 0.8585 - val_f1_score: 0.8632 - relative: 52.9761\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.1210 - accuracy: 0.9694 - f1_score: 0.9688 - val_loss: 0.6024 - val_accuracy: 0.8293 - val_f1_score: 0.8318 - relative: 53.9628\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0669 - accuracy: 0.9767 - f1_score: 0.9765 - val_loss: 0.5731 - val_accuracy: 0.8732 - val_f1_score: 0.8744 - relative: 54.9102\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0526 - accuracy: 0.9877 - f1_score: 0.9876 - val_loss: 0.5790 - val_accuracy: 0.8683 - val_f1_score: 0.8713 - relative: 55.8449\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0345 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.5667 - val_accuracy: 0.8683 - val_f1_score: 0.8684 - relative: 56.8146\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0571 - accuracy: 0.9853 - f1_score: 0.9853 - val_loss: 0.7531 - val_accuracy: 0.8390 - val_f1_score: 0.8401 - relative: 57.7366\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1258 - accuracy: 0.9608 - f1_score: 0.9604 - val_loss: 0.5345 - val_accuracy: 0.8585 - val_f1_score: 0.8635 - relative: 58.6684\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1157 - accuracy: 0.9681 - f1_score: 0.9681 - val_loss: 0.6050 - val_accuracy: 0.8244 - val_f1_score: 0.8252 - relative: 59.5704\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1285 - accuracy: 0.9522 - f1_score: 0.9522 - val_loss: 0.4847 - val_accuracy: 0.8537 - val_f1_score: 0.8576 - relative: 60.5094\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.2287 - accuracy: 0.9350 - f1_score: 0.9344 - val_loss: 0.7151 - val_accuracy: 0.7902 - val_f1_score: 0.7900 - relative: 61.4157\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.1570 - accuracy: 0.9485 - f1_score: 0.9483 - val_loss: 0.6372 - val_accuracy: 0.8537 - val_f1_score: 0.8584 - relative: 62.3683\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1701 - accuracy: 0.9449 - f1_score: 0.9447 - val_loss: 0.3905 - val_accuracy: 0.8976 - val_f1_score: 0.9014 - relative: 63.3167\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1647 - accuracy: 0.9522 - f1_score: 0.9522 - val_loss: 0.4309 - val_accuracy: 0.8732 - val_f1_score: 0.8770 - relative: 64.2437\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1398 - accuracy: 0.9571 - f1_score: 0.9569 - val_loss: 0.5183 - val_accuracy: 0.8780 - val_f1_score: 0.8816 - relative: 65.1614\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1246 - accuracy: 0.9608 - f1_score: 0.9602 - val_loss: 0.4244 - val_accuracy: 0.8878 - val_f1_score: 0.8904 - relative: 66.0971\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1679 - accuracy: 0.9461 - f1_score: 0.9456 - val_loss: 0.6066 - val_accuracy: 0.8439 - val_f1_score: 0.8462 - relative: 67.0310\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.1219 - accuracy: 0.9522 - f1_score: 0.9519 - val_loss: 0.6461 - val_accuracy: 0.8488 - val_f1_score: 0.8536 - relative: 67.9409\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.1432 - accuracy: 0.9657 - f1_score: 0.9653 - val_loss: 0.5559 - val_accuracy: 0.8488 - val_f1_score: 0.8521 - relative: 68.8739\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0955 - accuracy: 0.9718 - f1_score: 0.9717 - val_loss: 0.5397 - val_accuracy: 0.8439 - val_f1_score: 0.8415 - relative: 69.8126\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0749 - accuracy: 0.9755 - f1_score: 0.9751 - val_loss: 0.5954 - val_accuracy: 0.8829 - val_f1_score: 0.8897 - relative: 70.7460\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0903 - accuracy: 0.9767 - f1_score: 0.9763 - val_loss: 0.4557 - val_accuracy: 0.8976 - val_f1_score: 0.9013 - relative: 71.6797\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0440 - accuracy: 0.9877 - f1_score: 0.9878 - val_loss: 0.4588 - val_accuracy: 0.8732 - val_f1_score: 0.8795 - relative: 72.5956\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0603 - accuracy: 0.9792 - f1_score: 0.9793 - val_loss: 0.5015 - val_accuracy: 0.8634 - val_f1_score: 0.8680 - relative: 73.5357\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0550 - accuracy: 0.9804 - f1_score: 0.9803 - val_loss: 0.6182 - val_accuracy: 0.8732 - val_f1_score: 0.8774 - relative: 74.4769\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0543 - accuracy: 0.9804 - f1_score: 0.9803 - val_loss: 0.4720 - val_accuracy: 0.8829 - val_f1_score: 0.8846 - relative: 75.3844\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0485 - accuracy: 0.9877 - f1_score: 0.9876 - val_loss: 0.3650 - val_accuracy: 0.8976 - val_f1_score: 0.9005 - relative: 76.3295\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.0168 - accuracy: 0.9926 - f1_score: 0.9926 - val_loss: 0.4850 - val_accuracy: 0.9024 - val_f1_score: 0.9055 - relative: 77.2581\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0325 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.4678 - val_accuracy: 0.8976 - val_f1_score: 0.9001 - relative: 79.0310\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0617 - accuracy: 0.9828 - f1_score: 0.9825 - val_loss: 0.4776 - val_accuracy: 0.8927 - val_f1_score: 0.8958 - relative: 79.9680\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0783 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.5740 - val_accuracy: 0.8780 - val_f1_score: 0.8832 - relative: 80.9251\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0713 - accuracy: 0.9755 - f1_score: 0.9752 - val_loss: 0.5491 - val_accuracy: 0.8634 - val_f1_score: 0.8677 - relative: 81.8588\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0831 - accuracy: 0.9779 - f1_score: 0.9772 - val_loss: 0.6245 - val_accuracy: 0.8488 - val_f1_score: 0.8560 - relative: 82.7702\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0981 - accuracy: 0.9730 - f1_score: 0.9726 - val_loss: 0.7516 - val_accuracy: 0.8488 - val_f1_score: 0.8524 - relative: 83.7463\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0911 - accuracy: 0.9694 - f1_score: 0.9693 - val_loss: 0.5391 - val_accuracy: 0.8732 - val_f1_score: 0.8762 - relative: 84.6673\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0699 - accuracy: 0.9828 - f1_score: 0.9828 - val_loss: 0.6254 - val_accuracy: 0.8634 - val_f1_score: 0.8671 - relative: 85.5823\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.0702 - accuracy: 0.9792 - f1_score: 0.9793 - val_loss: 0.5846 - val_accuracy: 0.8683 - val_f1_score: 0.8723 - relative: 86.5705\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0739 - accuracy: 0.9767 - f1_score: 0.9766 - val_loss: 0.5795 - val_accuracy: 0.8634 - val_f1_score: 0.8669 - relative: 87.4831\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0692 - accuracy: 0.9828 - f1_score: 0.9830 - val_loss: 0.5494 - val_accuracy: 0.8683 - val_f1_score: 0.8731 - relative: 88.3901\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0691 - accuracy: 0.9792 - f1_score: 0.9789 - val_loss: 0.5247 - val_accuracy: 0.8732 - val_f1_score: 0.8754 - relative: 89.3434\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.0228 - accuracy: 0.9939 - f1_score: 0.9939 - val_loss: 0.5219 - val_accuracy: 0.8927 - val_f1_score: 0.8943 - relative: 90.2628\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0856 - accuracy: 0.9804 - f1_score: 0.9801 - val_loss: 0.6071 - val_accuracy: 0.8537 - val_f1_score: 0.8624 - relative: 91.2108\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.0659 - accuracy: 0.9841 - f1_score: 0.9836 - val_loss: 0.4720 - val_accuracy: 0.8976 - val_f1_score: 0.9020 - relative: 92.1783\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0253 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.4059 - val_accuracy: 0.9220 - val_f1_score: 0.9225 - relative: 93.1050\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0268 - accuracy: 0.9926 - f1_score: 0.9927 - val_loss: 0.4200 - val_accuracy: 0.9171 - val_f1_score: 0.9215 - relative: 94.7031\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0035 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9122 - val_f1_score: 0.9162 - relative: 95.6436\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.0028 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9317 - val_f1_score: 0.9352 - relative: 96.6333\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9317 - val_f1_score: 0.9352 - relative: 98.0168\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9317 - val_f1_score: 0.9352 - relative: 98.9516\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 8.5810e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9268 - val_f1_score: 0.9309 - relative: 99.8806\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 8.4160e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9268 - val_f1_score: 0.9309 - relative: 100.8232\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.8582e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9268 - val_f1_score: 0.9309 - relative: 101.7540\n",
      "Epoch 95/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 7.4119e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 7.5450e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9268 - val_f1_score: 0.9309 - relative: 102.7027\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_lstm_dset3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_lstm_dset3', history)\n",
    "model.save('models/lstm_dset3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 34, 1024)         8777728   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 34, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,077,449\n",
      "Trainable params: 12,076,937\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bilstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 14s 170ms/step - loss: 1.7387 - accuracy: 0.4277 - f1_score: 0.3694 - val_loss: 1.6666 - val_accuracy: 0.4732 - val_f1_score: 0.4511 - relative: 14.1277\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 1.1785 - accuracy: 0.5956 - f1_score: 0.5706 - val_loss: 1.4141 - val_accuracy: 0.5171 - val_f1_score: 0.5307 - relative: 15.9859\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.8922 - accuracy: 0.7034 - f1_score: 0.6935 - val_loss: 1.2468 - val_accuracy: 0.6341 - val_f1_score: 0.6457 - relative: 18.4913\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6890 - accuracy: 0.7586 - f1_score: 0.7547 - val_loss: 1.0597 - val_accuracy: 0.6780 - val_f1_score: 0.6876 - relative: 20.9204\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.5576 - accuracy: 0.8051 - f1_score: 0.8021 - val_loss: 0.8823 - val_accuracy: 0.7317 - val_f1_score: 0.7338 - relative: 23.4250\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.4790 - accuracy: 0.8407 - f1_score: 0.8378 - val_loss: 0.7947 - val_accuracy: 0.6976 - val_f1_score: 0.6898 - relative: 25.9592\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.4523 - accuracy: 0.8382 - f1_score: 0.8358 - val_loss: 0.7473 - val_accuracy: 0.7463 - val_f1_score: 0.7496 - relative: 27.7229\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.3768 - accuracy: 0.8750 - f1_score: 0.8730 - val_loss: 0.6157 - val_accuracy: 0.7854 - val_f1_score: 0.7834 - relative: 30.1511\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.2894 - accuracy: 0.9056 - f1_score: 0.9045 - val_loss: 0.7800 - val_accuracy: 0.7415 - val_f1_score: 0.7325 - relative: 32.6506\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.3212 - accuracy: 0.8811 - f1_score: 0.8785 - val_loss: 0.5908 - val_accuracy: 0.7951 - val_f1_score: 0.7993 - relative: 34.3342\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.2742 - accuracy: 0.9179 - f1_score: 0.9169 - val_loss: 0.7089 - val_accuracy: 0.7756 - val_f1_score: 0.7817 - relative: 36.7197\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.2384 - accuracy: 0.9265 - f1_score: 0.9258 - val_loss: 0.5828 - val_accuracy: 0.8098 - val_f1_score: 0.8122 - relative: 38.3673\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1907 - accuracy: 0.9387 - f1_score: 0.9381 - val_loss: 0.5358 - val_accuracy: 0.8098 - val_f1_score: 0.8114 - relative: 40.7388\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.1573 - accuracy: 0.9412 - f1_score: 0.9405 - val_loss: 0.4202 - val_accuracy: 0.8732 - val_f1_score: 0.8732 - relative: 42.4067\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1664 - accuracy: 0.9534 - f1_score: 0.9526 - val_loss: 0.5716 - val_accuracy: 0.8341 - val_f1_score: 0.8361 - relative: 44.9507\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.1892 - accuracy: 0.9400 - f1_score: 0.9391 - val_loss: 0.5140 - val_accuracy: 0.8293 - val_f1_score: 0.8344 - relative: 46.8190\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1723 - accuracy: 0.9436 - f1_score: 0.9431 - val_loss: 0.6038 - val_accuracy: 0.8341 - val_f1_score: 0.8382 - relative: 48.4966\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.2134 - accuracy: 0.9277 - f1_score: 0.9271 - val_loss: 0.7027 - val_accuracy: 0.7854 - val_f1_score: 0.7895 - relative: 50.2112\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.1614 - accuracy: 0.9424 - f1_score: 0.9414 - val_loss: 0.5256 - val_accuracy: 0.8780 - val_f1_score: 0.8780 - relative: 51.9055\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1346 - accuracy: 0.9559 - f1_score: 0.9552 - val_loss: 0.5667 - val_accuracy: 0.8195 - val_f1_score: 0.8219 - relative: 54.5189\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.1303 - accuracy: 0.9620 - f1_score: 0.9615 - val_loss: 0.6893 - val_accuracy: 0.8293 - val_f1_score: 0.8322 - relative: 56.2026\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.1040 - accuracy: 0.9718 - f1_score: 0.9714 - val_loss: 0.5554 - val_accuracy: 0.8293 - val_f1_score: 0.8364 - relative: 57.8853\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1188 - accuracy: 0.9608 - f1_score: 0.9600 - val_loss: 0.6875 - val_accuracy: 0.8195 - val_f1_score: 0.8196 - relative: 59.5489\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1328 - accuracy: 0.9571 - f1_score: 0.9568 - val_loss: 0.5904 - val_accuracy: 0.8439 - val_f1_score: 0.8435 - relative: 61.2228\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 2s 97ms/step - loss: 0.0942 - accuracy: 0.9681 - f1_score: 0.9679 - val_loss: 0.4728 - val_accuracy: 0.8829 - val_f1_score: 0.8871 - relative: 62.8714\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.0601 - accuracy: 0.9841 - f1_score: 0.9841 - val_loss: 0.3982 - val_accuracy: 0.9073 - val_f1_score: 0.9099 - relative: 65.3871\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0815 - accuracy: 0.9718 - f1_score: 0.9713 - val_loss: 0.5736 - val_accuracy: 0.8390 - val_f1_score: 0.8432 - relative: 67.6433\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0733 - accuracy: 0.9779 - f1_score: 0.9778 - val_loss: 0.4523 - val_accuracy: 0.8634 - val_f1_score: 0.8692 - relative: 69.2839\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0594 - accuracy: 0.9743 - f1_score: 0.9737 - val_loss: 0.5297 - val_accuracy: 0.8634 - val_f1_score: 0.8683 - relative: 70.9529\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1084 - accuracy: 0.9657 - f1_score: 0.9650 - val_loss: 0.5926 - val_accuracy: 0.8585 - val_f1_score: 0.8590 - relative: 72.5924\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1198 - accuracy: 0.9510 - f1_score: 0.9502 - val_loss: 0.5406 - val_accuracy: 0.8488 - val_f1_score: 0.8510 - relative: 74.2335\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1352 - accuracy: 0.9608 - f1_score: 0.9599 - val_loss: 0.5132 - val_accuracy: 0.8585 - val_f1_score: 0.8606 - relative: 75.8873\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0656 - accuracy: 0.9816 - f1_score: 0.9815 - val_loss: 0.6192 - val_accuracy: 0.8537 - val_f1_score: 0.8552 - relative: 77.5487\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0868 - accuracy: 0.9718 - f1_score: 0.9715 - val_loss: 0.5459 - val_accuracy: 0.8390 - val_f1_score: 0.8392 - relative: 79.1500\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0740 - accuracy: 0.9767 - f1_score: 0.9767 - val_loss: 0.6142 - val_accuracy: 0.8585 - val_f1_score: 0.8614 - relative: 80.7726\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1060 - accuracy: 0.9669 - f1_score: 0.9661 - val_loss: 0.5574 - val_accuracy: 0.8537 - val_f1_score: 0.8595 - relative: 82.3986\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0741 - accuracy: 0.9792 - f1_score: 0.9789 - val_loss: 0.6679 - val_accuracy: 0.8390 - val_f1_score: 0.8384 - relative: 84.0343\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0948 - accuracy: 0.9718 - f1_score: 0.9713 - val_loss: 0.7004 - val_accuracy: 0.8244 - val_f1_score: 0.8245 - relative: 85.7243\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0927 - accuracy: 0.9718 - f1_score: 0.9717 - val_loss: 0.5261 - val_accuracy: 0.8732 - val_f1_score: 0.8745 - relative: 87.3872\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0457 - accuracy: 0.9853 - f1_score: 0.9852 - val_loss: 0.6373 - val_accuracy: 0.8683 - val_f1_score: 0.8696 - relative: 89.0629\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0575 - accuracy: 0.9841 - f1_score: 0.9838 - val_loss: 0.5833 - val_accuracy: 0.8537 - val_f1_score: 0.8555 - relative: 90.7584\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.0525 - accuracy: 0.9816 - f1_score: 0.9817 - val_loss: 0.7370 - val_accuracy: 0.8537 - val_f1_score: 0.8582 - relative: 92.4919\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0972 - accuracy: 0.9694 - f1_score: 0.9690 - val_loss: 0.4471 - val_accuracy: 0.8976 - val_f1_score: 0.8981 - relative: 94.1808\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0602 - accuracy: 0.9841 - f1_score: 0.9839 - val_loss: 0.5134 - val_accuracy: 0.8927 - val_f1_score: 0.8953 - relative: 95.8496\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0527 - accuracy: 0.9828 - f1_score: 0.9825 - val_loss: 0.5342 - val_accuracy: 0.8439 - val_f1_score: 0.8481 - relative: 97.5175\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0838 - accuracy: 0.9730 - f1_score: 0.9721 - val_loss: 0.5938 - val_accuracy: 0.8195 - val_f1_score: 0.8266 - relative: 99.1643\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0916 - accuracy: 0.9779 - f1_score: 0.9775 - val_loss: 0.6103 - val_accuracy: 0.8146 - val_f1_score: 0.8239 - relative: 100.8102\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1150 - accuracy: 0.9645 - f1_score: 0.9635 - val_loss: 0.4783 - val_accuracy: 0.8878 - val_f1_score: 0.8899 - relative: 102.4402\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0843 - accuracy: 0.9706 - f1_score: 0.9701 - val_loss: 0.6105 - val_accuracy: 0.8537 - val_f1_score: 0.8548 - relative: 104.1036\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1153 - accuracy: 0.9608 - f1_score: 0.9603 - val_loss: 0.6561 - val_accuracy: 0.8244 - val_f1_score: 0.8254 - relative: 105.7742\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1226 - accuracy: 0.9620 - f1_score: 0.9618 - val_loss: 0.5917 - val_accuracy: 0.8634 - val_f1_score: 0.8673 - relative: 107.4367\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0996 - accuracy: 0.9694 - f1_score: 0.9692 - val_loss: 0.6122 - val_accuracy: 0.8390 - val_f1_score: 0.8433 - relative: 109.0689\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.1280 - accuracy: 0.9547 - f1_score: 0.9541 - val_loss: 0.5951 - val_accuracy: 0.8732 - val_f1_score: 0.8774 - relative: 110.7284\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.1332 - accuracy: 0.9706 - f1_score: 0.9701 - val_loss: 0.6639 - val_accuracy: 0.8049 - val_f1_score: 0.8058 - relative: 112.3711\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0703 - accuracy: 0.9730 - f1_score: 0.9728 - val_loss: 0.4382 - val_accuracy: 0.8732 - val_f1_score: 0.8743 - relative: 114.0026\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0337 - accuracy: 0.9890 - f1_score: 0.9888 - val_loss: 0.5531 - val_accuracy: 0.8732 - val_f1_score: 0.8755 - relative: 115.6253\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0162 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.5202 - val_accuracy: 0.8732 - val_f1_score: 0.8739 - relative: 117.2456\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0125 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.5301 - val_accuracy: 0.8585 - val_f1_score: 0.8608 - relative: 118.9186\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.0113 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.4014 - val_accuracy: 0.9122 - val_f1_score: 0.9139 - relative: 120.5809\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.0045 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.4611 - val_accuracy: 0.9073 - val_f1_score: 0.9102 - relative: 122.8708\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0188 - accuracy: 0.9939 - f1_score: 0.9936 - val_loss: 0.4691 - val_accuracy: 0.8927 - val_f1_score: 0.8955 - relative: 124.5147\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.0364 - accuracy: 0.9877 - f1_score: 0.9873 - val_loss: 0.4970 - val_accuracy: 0.8780 - val_f1_score: 0.8799 - relative: 126.2438\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0123 - accuracy: 0.9963 - f1_score: 0.9961 - val_loss: 0.5099 - val_accuracy: 0.8683 - val_f1_score: 0.8730 - relative: 127.9089\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.0058 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8829 - val_f1_score: 0.8852 - relative: 129.5953\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0165 - accuracy: 0.9951 - f1_score: 0.9950 - val_loss: 0.5176 - val_accuracy: 0.8878 - val_f1_score: 0.8898 - relative: 131.2400\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0090 - accuracy: 0.9963 - f1_score: 0.9962 - val_loss: 0.5226 - val_accuracy: 0.8634 - val_f1_score: 0.8663 - relative: 132.8880\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.0136 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.5081 - val_accuracy: 0.8780 - val_f1_score: 0.8808 - relative: 134.5572\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0068 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.4751 - val_accuracy: 0.8829 - val_f1_score: 0.8884 - relative: 136.1900\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.0016 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8780 - val_f1_score: 0.8818 - relative: 137.8281\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 4.5953e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.8780 - val_f1_score: 0.8818 - relative: 139.4538\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 4.1564e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8780 - val_f1_score: 0.8818 - relative: 141.1299\n",
      "Epoch 72/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 4.1673e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 4.1334e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8829 - val_f1_score: 0.8873 - relative: 142.8341\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_bilstm_dset3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_bilstm_dset3', history)\n",
    "model.save('models/bilstm_dset3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 4\n",
    "Component: Mouth, Upper Body, Right Hand, and Left Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets4.h5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    x_val = np.array(hf.get('x_val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 34, 512)           1759232   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 34, 256)           787456    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,754,953\n",
      "Trainable params: 2,754,697\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 7s 83ms/step - loss: 0.9327 - accuracy: 0.6887 - f1_score: 0.6743 - val_loss: 0.9509 - val_accuracy: 0.8537 - val_f1_score: 0.8555 - relative: 7.2643\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.3170 - accuracy: 0.8946 - f1_score: 0.8937 - val_loss: 0.5939 - val_accuracy: 0.8829 - val_f1_score: 0.8880 - relative: 8.1207\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.2099 - accuracy: 0.9301 - f1_score: 0.9298 - val_loss: 0.4953 - val_accuracy: 0.8732 - val_f1_score: 0.8763 - relative: 9.2487\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.2016 - accuracy: 0.9277 - f1_score: 0.9271 - val_loss: 0.3278 - val_accuracy: 0.9171 - val_f1_score: 0.9217 - relative: 10.0514\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1517 - accuracy: 0.9498 - f1_score: 0.9490 - val_loss: 0.3882 - val_accuracy: 0.8927 - val_f1_score: 0.8975 - relative: 11.5780\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.1739 - accuracy: 0.9424 - f1_score: 0.9423 - val_loss: 0.1715 - val_accuracy: 0.9512 - val_f1_score: 0.9528 - relative: 12.3883\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1196 - accuracy: 0.9645 - f1_score: 0.9643 - val_loss: 0.2390 - val_accuracy: 0.9268 - val_f1_score: 0.9315 - relative: 13.5887\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1285 - accuracy: 0.9596 - f1_score: 0.9589 - val_loss: 0.1594 - val_accuracy: 0.9512 - val_f1_score: 0.9542 - relative: 14.3726\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.1117 - accuracy: 0.9632 - f1_score: 0.9627 - val_loss: 0.1553 - val_accuracy: 0.9610 - val_f1_score: 0.9636 - relative: 15.1154\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0490 - accuracy: 0.9828 - f1_score: 0.9825 - val_loss: 0.1311 - val_accuracy: 0.9610 - val_f1_score: 0.9641 - relative: 16.3436\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0807 - accuracy: 0.9730 - f1_score: 0.9723 - val_loss: 0.2809 - val_accuracy: 0.9366 - val_f1_score: 0.9413 - relative: 17.1407\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0906 - accuracy: 0.9743 - f1_score: 0.9741 - val_loss: 0.2879 - val_accuracy: 0.9366 - val_f1_score: 0.9418 - relative: 17.9568\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0711 - accuracy: 0.9779 - f1_score: 0.9777 - val_loss: 0.2560 - val_accuracy: 0.9317 - val_f1_score: 0.9364 - relative: 18.7519\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.2123 - accuracy: 0.9265 - f1_score: 0.9265 - val_loss: 0.1534 - val_accuracy: 0.9463 - val_f1_score: 0.9496 - relative: 19.5757\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.0697 - accuracy: 0.9828 - f1_score: 0.9829 - val_loss: 0.1226 - val_accuracy: 0.9659 - val_f1_score: 0.9686 - relative: 20.3669\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1218 - accuracy: 0.9681 - f1_score: 0.9678 - val_loss: 0.5350 - val_accuracy: 0.8439 - val_f1_score: 0.8429 - relative: 21.5512\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1547 - accuracy: 0.9498 - f1_score: 0.9496 - val_loss: 0.1646 - val_accuracy: 0.9512 - val_f1_score: 0.9546 - relative: 22.3450\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1349 - accuracy: 0.9620 - f1_score: 0.9615 - val_loss: 0.3339 - val_accuracy: 0.9122 - val_f1_score: 0.9176 - relative: 23.1148\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1373 - accuracy: 0.9669 - f1_score: 0.9666 - val_loss: 0.3776 - val_accuracy: 0.9122 - val_f1_score: 0.9187 - relative: 23.9206\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.0813 - accuracy: 0.9706 - f1_score: 0.9701 - val_loss: 0.3060 - val_accuracy: 0.9220 - val_f1_score: 0.9271 - relative: 24.7944\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.1759 - accuracy: 0.9485 - f1_score: 0.9482 - val_loss: 0.3240 - val_accuracy: 0.9171 - val_f1_score: 0.9221 - relative: 25.6472\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.1241 - accuracy: 0.9620 - f1_score: 0.9618 - val_loss: 0.1630 - val_accuracy: 0.9415 - val_f1_score: 0.9450 - relative: 26.4555\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0562 - accuracy: 0.9865 - f1_score: 0.9865 - val_loss: 0.1410 - val_accuracy: 0.9659 - val_f1_score: 0.9684 - relative: 27.2557\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.0141 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.1461 - val_accuracy: 0.9707 - val_f1_score: 0.9735 - relative: 28.0340\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.0060 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.1760 - val_accuracy: 0.9561 - val_f1_score: 0.9599 - relative: 29.3066\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0137 - accuracy: 0.9975 - f1_score: 0.9975 - val_loss: 0.1746 - val_accuracy: 0.9561 - val_f1_score: 0.9599 - relative: 30.0761\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0033 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9610 - val_f1_score: 0.9642 - relative: 30.8629\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9707 - val_f1_score: 0.9735 - relative: 31.6605\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9707 - val_f1_score: 0.9735 - relative: 32.4709\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_lstm_dset4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_lstm_dset4', history)\n",
    "model.save('models/lstm_dset4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 34, 1024)         3518464   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 34, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,818,185\n",
      "Trainable params: 6,817,673\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bilstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 15s 150ms/step - loss: 1.0183 - accuracy: 0.6863 - f1_score: 0.6773 - val_loss: 0.9091 - val_accuracy: 0.8146 - val_f1_score: 0.8220 - relative: 16.9823\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.3371 - accuracy: 0.8934 - f1_score: 0.8929 - val_loss: 0.4755 - val_accuracy: 0.9220 - val_f1_score: 0.9239 - relative: 18.4513\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.1724 - accuracy: 0.9522 - f1_score: 0.9521 - val_loss: 0.3389 - val_accuracy: 0.9317 - val_f1_score: 0.9370 - relative: 20.4627\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.1638 - accuracy: 0.9547 - f1_score: 0.9540 - val_loss: 0.2563 - val_accuracy: 0.9317 - val_f1_score: 0.9343 - relative: 22.6731\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.1142 - accuracy: 0.9718 - f1_score: 0.9715 - val_loss: 0.2533 - val_accuracy: 0.9366 - val_f1_score: 0.9401 - relative: 24.1043\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.1426 - accuracy: 0.9632 - f1_score: 0.9630 - val_loss: 0.2309 - val_accuracy: 0.9317 - val_f1_score: 0.9359 - relative: 26.1217\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0985 - accuracy: 0.9694 - f1_score: 0.9690 - val_loss: 0.1921 - val_accuracy: 0.9268 - val_f1_score: 0.9297 - relative: 27.4461\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0768 - accuracy: 0.9718 - f1_score: 0.9717 - val_loss: 0.2835 - val_accuracy: 0.9171 - val_f1_score: 0.9211 - relative: 28.7598\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.1170 - accuracy: 0.9718 - f1_score: 0.9715 - val_loss: 0.1963 - val_accuracy: 0.9415 - val_f1_score: 0.9457 - relative: 30.0745\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.1152 - accuracy: 0.9657 - f1_score: 0.9657 - val_loss: 0.2021 - val_accuracy: 0.9366 - val_f1_score: 0.9398 - relative: 32.1113\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.0947 - accuracy: 0.9681 - f1_score: 0.9676 - val_loss: 0.1181 - val_accuracy: 0.9610 - val_f1_score: 0.9626 - relative: 33.4197\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0666 - accuracy: 0.9828 - f1_score: 0.9827 - val_loss: 0.1976 - val_accuracy: 0.9415 - val_f1_score: 0.9447 - relative: 35.4901\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0445 - accuracy: 0.9841 - f1_score: 0.9840 - val_loss: 0.1726 - val_accuracy: 0.9561 - val_f1_score: 0.9585 - relative: 36.8207\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.0231 - accuracy: 0.9939 - f1_score: 0.9939 - val_loss: 0.1290 - val_accuracy: 0.9707 - val_f1_score: 0.9723 - relative: 38.1270\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.0710 - accuracy: 0.9828 - f1_score: 0.9822 - val_loss: 0.1874 - val_accuracy: 0.9756 - val_f1_score: 0.9772 - relative: 40.2127\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0310 - accuracy: 0.9951 - f1_score: 0.9951 - val_loss: 0.1504 - val_accuracy: 0.9659 - val_f1_score: 0.9676 - relative: 42.3414\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0611 - accuracy: 0.9816 - f1_score: 0.9812 - val_loss: 0.1156 - val_accuracy: 0.9659 - val_f1_score: 0.9677 - relative: 43.7294\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0757 - accuracy: 0.9853 - f1_score: 0.9849 - val_loss: 0.1915 - val_accuracy: 0.9561 - val_f1_score: 0.9583 - relative: 45.0989\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0229 - accuracy: 0.9939 - f1_score: 0.9937 - val_loss: 0.1399 - val_accuracy: 0.9610 - val_f1_score: 0.9630 - relative: 46.4409\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0107 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.1538 - val_accuracy: 0.9610 - val_f1_score: 0.9622 - relative: 47.7375\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.0102 - accuracy: 0.9988 - f1_score: 0.9988 - val_loss: 0.1299 - val_accuracy: 0.9805 - val_f1_score: 0.9822 - relative: 49.0698\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0020 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9707 - val_f1_score: 0.9720 - relative: 51.1347\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9707 - val_f1_score: 0.9720 - relative: 52.4708\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 9.5023e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9756 - val_f1_score: 0.9772 - relative: 53.8512\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 6.5467e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9805 - val_f1_score: 0.9822 - relative: 55.1654\n",
      "Epoch 26/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 5.8597e-04 - accuracy: 1.0000 - f1_score: 1.0000Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 6.2507e-04 - accuracy: 1.0000 - f1_score: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9805 - val_f1_score: 0.9822 - relative: 56.5460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_bilstm_dset4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_bilstm_dset4', history)\n",
    "model.save('models/bilstm_dset4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 5\n",
    "Component: Right Hand and Left Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/.preprocessed_data/datasets5.h5','r') as hf:\n",
    "    x_train = np.array(hf.get('x_train'))\n",
    "    x_val = np.array(hf.get('x_val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 34, 512)           1308672   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 34, 256)           787456    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,304,393\n",
      "Trainable params: 2,304,137\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 7s 83ms/step - loss: 0.8817 - accuracy: 0.7292 - f1_score: 0.7284 - val_loss: 0.9407 - val_accuracy: 0.8732 - val_f1_score: 0.8731 - relative: 6.8311\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3723 - accuracy: 0.8738 - f1_score: 0.8724 - val_loss: 0.6888 - val_accuracy: 0.8488 - val_f1_score: 0.8480 - relative: 7.6494\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.2513 - accuracy: 0.9240 - f1_score: 0.9237 - val_loss: 0.5000 - val_accuracy: 0.8732 - val_f1_score: 0.8802 - relative: 8.4258\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.2422 - accuracy: 0.9326 - f1_score: 0.9322 - val_loss: 0.3899 - val_accuracy: 0.9220 - val_f1_score: 0.9235 - relative: 9.1832\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1618 - accuracy: 0.9485 - f1_score: 0.9481 - val_loss: 0.3571 - val_accuracy: 0.9073 - val_f1_score: 0.9126 - relative: 10.2951\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2800 - accuracy: 0.9154 - f1_score: 0.9145 - val_loss: 0.3822 - val_accuracy: 0.9073 - val_f1_score: 0.9118 - relative: 11.0169\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.2923 - accuracy: 0.9044 - f1_score: 0.9041 - val_loss: 0.5208 - val_accuracy: 0.8683 - val_f1_score: 0.8702 - relative: 11.8051\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.2979 - accuracy: 0.9020 - f1_score: 0.9016 - val_loss: 0.1956 - val_accuracy: 0.9415 - val_f1_score: 0.9444 - relative: 12.6069\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1538 - accuracy: 0.9608 - f1_score: 0.9606 - val_loss: 0.1814 - val_accuracy: 0.9415 - val_f1_score: 0.9430 - relative: 13.6701\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.2067 - accuracy: 0.9265 - f1_score: 0.9263 - val_loss: 0.2576 - val_accuracy: 0.9366 - val_f1_score: 0.9406 - relative: 14.4203\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1824 - accuracy: 0.9498 - f1_score: 0.9488 - val_loss: 0.2227 - val_accuracy: 0.9317 - val_f1_score: 0.9323 - relative: 15.1761\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.1246 - accuracy: 0.9681 - f1_score: 0.9679 - val_loss: 0.2269 - val_accuracy: 0.9512 - val_f1_score: 0.9547 - relative: 15.9174\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1559 - accuracy: 0.9534 - f1_score: 0.9530 - val_loss: 0.2223 - val_accuracy: 0.9463 - val_f1_score: 0.9490 - relative: 17.0085\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0994 - accuracy: 0.9608 - f1_score: 0.9608 - val_loss: 0.1535 - val_accuracy: 0.9561 - val_f1_score: 0.9593 - relative: 17.7316\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0657 - accuracy: 0.9767 - f1_score: 0.9766 - val_loss: 0.2891 - val_accuracy: 0.9415 - val_f1_score: 0.9445 - relative: 18.8654\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0840 - accuracy: 0.9706 - f1_score: 0.9705 - val_loss: 0.1864 - val_accuracy: 0.9512 - val_f1_score: 0.9536 - relative: 19.6531\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.0635 - accuracy: 0.9779 - f1_score: 0.9777 - val_loss: 0.1870 - val_accuracy: 0.9610 - val_f1_score: 0.9648 - relative: 20.3647\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0276 - accuracy: 0.9914 - f1_score: 0.9914 - val_loss: 0.2133 - val_accuracy: 0.9610 - val_f1_score: 0.9626 - relative: 21.4446\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0262 - accuracy: 0.9914 - f1_score: 0.9914 - val_loss: 0.2213 - val_accuracy: 0.9610 - val_f1_score: 0.9629 - relative: 22.1990\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0134 - accuracy: 0.9939 - f1_score: 0.9938 - val_loss: 0.2239 - val_accuracy: 0.9659 - val_f1_score: 0.9676 - relative: 22.9179\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.0279 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.1690 - val_accuracy: 0.9707 - val_f1_score: 0.9734 - relative: 24.0940\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1371 - accuracy: 0.9706 - f1_score: 0.9704 - val_loss: 0.3969 - val_accuracy: 0.9317 - val_f1_score: 0.9378 - relative: 25.1256\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.1184 - accuracy: 0.9596 - f1_score: 0.9592 - val_loss: 0.2365 - val_accuracy: 0.9561 - val_f1_score: 0.9591 - relative: 25.8966\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1731 - accuracy: 0.9547 - f1_score: 0.9538 - val_loss: 0.3181 - val_accuracy: 0.9122 - val_f1_score: 0.9187 - relative: 26.6505\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.2519 - accuracy: 0.9289 - f1_score: 0.9281 - val_loss: 0.2486 - val_accuracy: 0.9366 - val_f1_score: 0.9406 - relative: 27.4074\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1402 - accuracy: 0.9645 - f1_score: 0.9646 - val_loss: 0.2939 - val_accuracy: 0.9317 - val_f1_score: 0.9314 - relative: 28.2191\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1329 - accuracy: 0.9596 - f1_score: 0.9591 - val_loss: 0.3210 - val_accuracy: 0.9415 - val_f1_score: 0.9451 - relative: 28.9684\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.1101 - accuracy: 0.9669 - f1_score: 0.9668 - val_loss: 0.2722 - val_accuracy: 0.9463 - val_f1_score: 0.9491 - relative: 29.7293\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0856 - accuracy: 0.9730 - f1_score: 0.9726 - val_loss: 0.2444 - val_accuracy: 0.9463 - val_f1_score: 0.9505 - relative: 30.5023\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0511 - accuracy: 0.9877 - f1_score: 0.9875 - val_loss: 0.1127 - val_accuracy: 0.9707 - val_f1_score: 0.9747 - relative: 31.2668\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0275 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.1967 - val_accuracy: 0.9707 - val_f1_score: 0.9735 - relative: 32.0041\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0358 - accuracy: 0.9914 - f1_score: 0.9913 - val_loss: 0.1325 - val_accuracy: 0.9707 - val_f1_score: 0.9738 - relative: 32.7649\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0350 - accuracy: 0.9902 - f1_score: 0.9900 - val_loss: 0.1596 - val_accuracy: 0.9707 - val_f1_score: 0.9733 - relative: 33.4891\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.0250 - accuracy: 0.9926 - f1_score: 0.9926 - val_loss: 0.1427 - val_accuracy: 0.9756 - val_f1_score: 0.9783 - relative: 34.2208\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0222 - accuracy: 0.9926 - f1_score: 0.9926 - val_loss: 0.1942 - val_accuracy: 0.9756 - val_f1_score: 0.9783 - relative: 35.4287\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0183 - accuracy: 0.9926 - f1_score: 0.9926 - val_loss: 0.2102 - val_accuracy: 0.9707 - val_f1_score: 0.9734 - relative: 36.1838\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0530 - accuracy: 0.9828 - f1_score: 0.9824 - val_loss: 0.2161 - val_accuracy: 0.9659 - val_f1_score: 0.9690 - relative: 36.9238\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0353 - accuracy: 0.9902 - f1_score: 0.9899 - val_loss: 0.2203 - val_accuracy: 0.9610 - val_f1_score: 0.9638 - relative: 37.6713\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.0278 - accuracy: 0.9877 - f1_score: 0.9875 - val_loss: 0.2789 - val_accuracy: 0.9561 - val_f1_score: 0.9599 - relative: 38.4690\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0368 - accuracy: 0.9902 - f1_score: 0.9901 - val_loss: 0.2885 - val_accuracy: 0.9610 - val_f1_score: 0.9647 - relative: 39.1843\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0382 - accuracy: 0.9865 - f1_score: 0.9864 - val_loss: 0.3064 - val_accuracy: 0.9463 - val_f1_score: 0.9495 - relative: 39.9437\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0338 - accuracy: 0.9902 - f1_score: 0.9901 - val_loss: 0.2127 - val_accuracy: 0.9610 - val_f1_score: 0.9640 - relative: 40.6755\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0297 - accuracy: 0.9865 - f1_score: 0.9865 - val_loss: 0.2137 - val_accuracy: 0.9707 - val_f1_score: 0.9738 - relative: 41.4589\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0319 - accuracy: 0.9902 - f1_score: 0.9901 - val_loss: 0.2544 - val_accuracy: 0.9659 - val_f1_score: 0.9682 - relative: 42.2326\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0601 - accuracy: 0.9779 - f1_score: 0.9776 - val_loss: 0.2457 - val_accuracy: 0.9610 - val_f1_score: 0.9638 - relative: 42.9967\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0219 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.2564 - val_accuracy: 0.9610 - val_f1_score: 0.9638 - relative: 43.7923\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.0136 - accuracy: 0.9963 - f1_score: 0.9963 - val_loss: 0.2351 - val_accuracy: 0.9659 - val_f1_score: 0.9688 - relative: 44.5750\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.0189 - accuracy: 0.9926 - f1_score: 0.9925 - val_loss: 0.2363 - val_accuracy: 0.9659 - val_f1_score: 0.9691 - relative: 45.3378\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9890 - f1_score: 0.9890Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0241 - accuracy: 0.9890 - f1_score: 0.9890 - val_loss: 0.2511 - val_accuracy: 0.9659 - val_f1_score: 0.9688 - relative: 46.0756\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_lstm_dset5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_lstm_dset5', history)\n",
    "model.save('models/lstm_dset5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 34, 1024)         2617344   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 34, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,917,065\n",
      "Trainable params: 5,916,553\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bilstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                  tfa.metrics.F1Score(NUM_LABELS),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 13s 152ms/step - loss: 0.9147 - accuracy: 0.6985 - f1_score: 0.6980 - val_loss: 0.9232 - val_accuracy: 0.8146 - val_f1_score: 0.8171 - relative: 12.8369\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.3850 - accuracy: 0.8836 - f1_score: 0.8832 - val_loss: 0.5014 - val_accuracy: 0.9220 - val_f1_score: 0.9237 - relative: 14.3072\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.2240 - accuracy: 0.9338 - f1_score: 0.9335 - val_loss: 0.3988 - val_accuracy: 0.9220 - val_f1_score: 0.9254 - relative: 16.3668\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.2368 - accuracy: 0.9130 - f1_score: 0.9126 - val_loss: 0.4640 - val_accuracy: 0.8390 - val_f1_score: 0.8459 - relative: 17.6612\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.1807 - accuracy: 0.9400 - f1_score: 0.9393 - val_loss: 0.2167 - val_accuracy: 0.9463 - val_f1_score: 0.9485 - relative: 19.0244\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.1301 - accuracy: 0.9534 - f1_score: 0.9532 - val_loss: 0.1617 - val_accuracy: 0.9610 - val_f1_score: 0.9626 - relative: 21.0465\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.1917 - accuracy: 0.9363 - f1_score: 0.9360 - val_loss: 0.2782 - val_accuracy: 0.9122 - val_f1_score: 0.9141 - relative: 23.0112\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.1566 - accuracy: 0.9449 - f1_score: 0.9437 - val_loss: 0.3204 - val_accuracy: 0.8732 - val_f1_score: 0.8790 - relative: 24.3458\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.1316 - accuracy: 0.9485 - f1_score: 0.9481 - val_loss: 0.3177 - val_accuracy: 0.9317 - val_f1_score: 0.9329 - relative: 25.6714\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.2142 - accuracy: 0.9289 - f1_score: 0.9281 - val_loss: 0.3097 - val_accuracy: 0.8878 - val_f1_score: 0.8923 - relative: 26.9788\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.1359 - accuracy: 0.9547 - f1_score: 0.9538 - val_loss: 0.1284 - val_accuracy: 0.9561 - val_f1_score: 0.9582 - relative: 28.2350\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.1051 - accuracy: 0.9657 - f1_score: 0.9654 - val_loss: 0.3631 - val_accuracy: 0.9073 - val_f1_score: 0.9114 - relative: 29.6002\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.1506 - accuracy: 0.9510 - f1_score: 0.9500 - val_loss: 0.1566 - val_accuracy: 0.9610 - val_f1_score: 0.9641 - relative: 30.9136\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.1091 - accuracy: 0.9669 - f1_score: 0.9666 - val_loss: 0.1642 - val_accuracy: 0.9512 - val_f1_score: 0.9544 - relative: 32.2208\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.1285 - accuracy: 0.9632 - f1_score: 0.9627 - val_loss: 0.1589 - val_accuracy: 0.9512 - val_f1_score: 0.9539 - relative: 33.4906\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.0665 - accuracy: 0.9767 - f1_score: 0.9765 - val_loss: 0.0995 - val_accuracy: 0.9610 - val_f1_score: 0.9621 - relative: 34.7703\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.0646 - accuracy: 0.9804 - f1_score: 0.9800 - val_loss: 0.0987 - val_accuracy: 0.9659 - val_f1_score: 0.9671 - relative: 36.0805\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.0518 - accuracy: 0.9841 - f1_score: 0.9837 - val_loss: 0.1021 - val_accuracy: 0.9756 - val_f1_score: 0.9771 - relative: 38.1844\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.0483 - accuracy: 0.9877 - f1_score: 0.9875 - val_loss: 0.0814 - val_accuracy: 0.9659 - val_f1_score: 0.9675 - relative: 40.0771\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.0678 - accuracy: 0.9767 - f1_score: 0.9763 - val_loss: 0.1201 - val_accuracy: 0.9561 - val_f1_score: 0.9581 - relative: 41.3294\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.0619 - accuracy: 0.9792 - f1_score: 0.9789 - val_loss: 0.1234 - val_accuracy: 0.9512 - val_f1_score: 0.9519 - relative: 42.6810\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0462 - accuracy: 0.9828 - f1_score: 0.9826 - val_loss: 0.0583 - val_accuracy: 0.9756 - val_f1_score: 0.9768 - relative: 43.9806\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.0457 - accuracy: 0.9865 - f1_score: 0.9862 - val_loss: 0.0479 - val_accuracy: 0.9854 - val_f1_score: 0.9855 - relative: 45.2914\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0324 - accuracy: 0.9902 - f1_score: 0.9900 - val_loss: 0.0754 - val_accuracy: 0.9805 - val_f1_score: 0.9811 - relative: 47.4215\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0413 - accuracy: 0.9865 - f1_score: 0.9862 - val_loss: 0.0425 - val_accuracy: 0.9854 - val_f1_score: 0.9857 - relative: 48.7126\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0390 - accuracy: 0.9853 - f1_score: 0.9851 - val_loss: 0.0852 - val_accuracy: 0.9756 - val_f1_score: 0.9767 - relative: 50.0257\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.0413 - accuracy: 0.9853 - f1_score: 0.9850 - val_loss: 0.0540 - val_accuracy: 0.9854 - val_f1_score: 0.9863 - relative: 51.3087\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.0288 - accuracy: 0.9890 - f1_score: 0.9889 - val_loss: 0.0495 - val_accuracy: 0.9854 - val_f1_score: 0.9857 - relative: 52.6815\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.0206 - accuracy: 0.9939 - f1_score: 0.9937 - val_loss: 0.0552 - val_accuracy: 0.9805 - val_f1_score: 0.9809 - relative: 53.9468\n",
      "Epoch 30/500\n",
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0231 - accuracy: 0.9900 - f1_score: 0.9898Training stopped due to no change in val_loss for 7 epochs.\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.0234 - accuracy: 0.9902 - f1_score: 0.9900 - val_loss: 0.0931 - val_accuracy: 0.9756 - val_f1_score: 0.9757 - relative: 55.2631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs = 500, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[noChangeStop, checkpoint('best_bilstm_dset5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log('history_bilstm_dset5', history)\n",
    "model.save('models/bilstm_dset5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model.reset_states()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for red in np.arange(1,6):\n",
    "    with h5py.File(f'data/.preprocessed_data/datasets{red}.h5','r') as hf:\n",
    "            x_train = np.array(hf.get('x_train'))\n",
    "            x_val = np.array(hf.get('x_val'))\n",
    "            \n",
    "    for bz in [16, 32, 64]:\n",
    "        for lr in [1E-3,1E-4,1E-5]:\n",
    "            for mod in ['lstm','bilstm']:\n",
    "                if 'lstm':\n",
    "                    model = lstm_model((x_train.shape[1],x_train.shape[2]))\n",
    "                elif 'bilstm':\n",
    "                    model = bilstm_model((x_train.shape[1],x_train.shape[2])) \n",
    "        \n",
    "                model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                        metrics=[\n",
    "                            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                            tfa.metrics.F1Score(NUM_LABELS),])\n",
    "        \n",
    "                history = model.fit(x_train,\n",
    "                                y_train,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                epochs = 500, \n",
    "                                batch_size=bz,\n",
    "                                callbacks=[noChangeStop, \n",
    "                                        checkpoint(f\"models3/v2/{bz}/best_{mod}_dset{red}_{lr}.h5\")])\n",
    "                \n",
    "                save_log(f'logs3/v2/{bz}/history_{mod}_dset{red}_{lr}.h5', history)\n",
    "                model.save(f\"models3/v2/{bz}/{mod}_dset{red}_{lr}.h5\")\n",
    "                \n",
    "                tf.keras.backend.clear_session()\n",
    "                model.reset_states()\n",
    "                del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
